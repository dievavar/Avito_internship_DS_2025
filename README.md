# Avito Internship DS 2025

Тестовое задание для стажировки в Avito (Data Science, 2025).  
Задача: восстановление пропущенных пробелов в тексте (поисковые запросы).

---

## Описание задачи
На Авито пользователи часто вводят тексты с опечатками и без пробелов (например: `куплюайфон14про`).  
Цель — разработать модель, которая принимает на вход слитный текст и возвращает корректный вариант с пробелами (`куплю айфон 14 про`).  

Можно использовать любые подходы:

-Классические NLP-методы: динамическое программирование + словарь + вероятностная модель (n-граммы, unigram)
-Предобученные токенизаторы (например, BPE, WordPiece)
-Модели с Hugging Face: BERT, RoBERTa, T5 — fine-tuning или zero-shot
-Комбинации: например, эвристики + модель

---

## Структура проекта
Avito_internship_DS_2025/

├── submission_3.csv - лучшее предсказание

├── Avito_internship_DS_2025_Dieva.ipynb - ноутбук с экспериментами

├── requirements.txt - зависимости окружения

└── README.md - документация

---
## Сравнение моделей

| Алгоритм             | Краткое описание                                                                 | Сильные стороны                          | Слабые стороны                          |
|-----------------------|----------------------------------------------------------------------------------|------------------------------------------|------------------------------------------|
| **Baseline (словарь)** | Деление строки по словарю частотных слов (динамическое программирование).        | Очень быстрое, простое решение           | Низкое качество, плохо работает с редкими словами |
| **BiLSTM**            | Двунаправленная LSTM классифицирует каждый символ (ставить пробел или нет).     | Учитывает контекст, лучше baseline       | Медленнее и хуже на длинных строках      |
| **BiLSTM + CRF**      | BiLSTM + слой CRF для согласованности меток.                                    | Улучшает последовательные предсказания   | Более сложное обучение                   |
| **Transformer Encoder** | Лёгкий трансформер с self-attention для посимвольной обработки.                 | Хорошо работает на длинных строках       | Требует больше ресурсов, чем LSTM        |
| **Transformer + CRF** | Encoder даёт эмбеддинги, CRF предсказывает пробелы как задачу разметки.         | Лучший баланс качества и стабильности    | Сложнее в реализации                     |
| **CNN + BiLSTM**      | CNN извлекает локальные паттерны, BiLSTM учитывает долгосрочный контекст.       | Быстрее трансформера, лучше baseline     | Хуже трансформера по качеству            |

---

## Автор
Диева Варвара

Тестовое задание на стажировку в Avito DS, 2025.

---
