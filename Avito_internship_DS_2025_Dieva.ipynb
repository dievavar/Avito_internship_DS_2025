{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ceabaf-4dfc-4269-b928-30d920547e21",
   "metadata": {},
   "source": [
    "# Восстановление пропущенных пробелов в тексте\n",
    "\n",
    "## Описание задачи\n",
    "На Авито пользователи часто вводят поисковые запросы и описания без пробелов, что снижает качество поиска и мешает анализу текста.  \n",
    "Нужно разработать лёгкую и быструю модель, которая принимает строку без пробелов и восстанавливает её правильный вариант.  \n",
    "\n",
    "Метрика: **F1-score** по позициям вставленных пробелов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde4a19-fa6b-475e-b83c-94b9c13e1cc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Библиотеки и пакеты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c87feb-aaf5-486b-8edb-9c82c7339d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from wordfreq import zipf_frequency\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d73a2-3356-45e3-84bc-4b395eed1ea4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Подготовка данных\n",
    "1. Загрузка сырых данных \n",
    "2. Первичный анализ данных (EDA)  \n",
    "3. Основные функции для работы  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b4758c5-fff9-4f7d-83f6-586a5b664f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_with_summary(path: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if not row:  \n",
    "                continue\n",
    "            if row[0] == \"id\":  \n",
    "                continue\n",
    "            id_ = int(row[0])  \n",
    "            text = \",\".join(row[1:]) \n",
    "            rows.append((id_, text))\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=[\"id\", \"text_no_spaces\"])\n",
    "    # df = df.set_index(\"id\")  \n",
    "    df[\"length\"] = df[\"text_no_spaces\"].str.len()\n",
    "    \n",
    "    # Дополнительные признаки\n",
    "    has_digits = df[\"text_no_spaces\"].str.contains(r\"\\d\").sum()\n",
    "    has_upper = df[\"text_no_spaces\"].str.contains(r\"[А-Я]\").sum()\n",
    "    has_latin = df[\"text_no_spaces\"].str.contains(r\"[A-Za-z]\").sum()\n",
    "\n",
    "    # Мини-EDA\n",
    "    print(\"Сводка по датасету\")\n",
    "    print(\"Размер датасета:\", df.shape)\n",
    "    print(\"Средняя длина:\", df[\"length\"].mean())\n",
    "    print(\"Мин длина:\", df[\"length\"].min())\n",
    "    print(\"Макс длина:\", df[\"length\"].max())\n",
    "    print(\"Строк с цифрами:\", has_digits)\n",
    "    print(\"Строк с заглавными буквами:\", has_upper)\n",
    "    print(\"Строк с латиницей:\", has_latin)\n",
    "    print()\n",
    "    print(df.info())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c7f5c20f-811c-4bcd-93ca-2ef4095f7a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сводка по датасету\n",
      "Размер датасета: (1005, 3)\n",
      "Средняя длина: 22.860696517412936\n",
      "Мин длина: 4\n",
      "Макс длина: 56\n",
      "Строк с цифрами: 26\n",
      "Строк с заглавными буквами: 589\n",
      "Строк с латиницей: 90\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1005 entries, 0 to 1004\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              1005 non-null   int64 \n",
      " 1   text_no_spaces  1005 non-null   object\n",
      " 2   length          1005 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 23.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 text_no_spaces  length\n",
       "0   0                куплюайфон14про      15\n",
       "1   1             ищудомвПодмосковье      18\n",
       "2   2  сдаюквартирусмебельюитехникой      29\n",
       "3   3     новыйдивандоставканедорого      26\n",
       "4   4                отдамдаромкошку      15"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_dataset_with_summary(\"Downloads/dataset_1937770_3.txt\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce43a48e-f2ae-4e2f-89a6-67ac7c741a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>ищукнигубратьякарамазовы,срочно</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>новыймонитор,27дюймов,доставка</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>куплюковрикдляйоги,недорого!</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>ищуинструкторапоплаванию,бассейнрядом</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>сдамкомнату,толькодевушке</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>куплюшвейнуюмашинку,рабочую</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>ищудрузейдляпутешествий,летомвгоры</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>новаякофеваркаPhilips,гарантияесть</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>куплюлыжи,палкивкомплекте</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>ищуучителяповокалу,джаз</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>сдамместовгараже,сухо</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                         text_no_spaces  length\n",
       "100  100        ищукнигубратьякарамазовы,срочно      31\n",
       "101  101         новыймонитор,27дюймов,доставка      30\n",
       "102  102           куплюковрикдляйоги,недорого!      28\n",
       "103  103  ищуинструкторапоплаванию,бассейнрядом      37\n",
       "104  104              сдамкомнату,толькодевушке      25\n",
       "105  105            куплюшвейнуюмашинку,рабочую      27\n",
       "106  106     ищудрузейдляпутешествий,летомвгоры      34\n",
       "107  107     новаякофеваркаPhilips,гарантияесть      34\n",
       "108  108              куплюлыжи,палкивкомплекте      25\n",
       "109  109                ищуучителяповокалу,джаз      23\n",
       "110  110                  сдамместовгараже,сухо      21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотреть строки с 100 по 110, где были запятые в предложениях - убеждаеся что все верно разбито\n",
    "df.iloc[100:111]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d1840-cbdf-4b48-91a8-957d6f84b641",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Первичный анализ данных (EDA)**\n",
    "\n",
    "Эти данные помогут определить, где потребуется использовать **эвристики** (например, обработка чисел, брендов, городов).  \n",
    "\n",
    "Перед построением модели важно изучить данные:\n",
    "- структура и длины строк,\n",
    "- наличие лишних символов (цифры, латиница, заглавные буквы),\n",
    "- потенциальные сложности (бренды, города, спецсимволы).\n",
    "\n",
    "При загрузке датасета через `pd.read_csv` возникала проблема:  \n",
    "если в тексте встречаются запятые, Pandas воспринимает их как разделители и создает несколько колонок вместо двух (`id, text_no_spaces`).\n",
    "\n",
    "Пример строки:  \"100,ищукнигубратьякарамазовы,срочно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2109f58f-3349-452c-980c-3af235d932a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Частота встречаемости цифр / латиницы / заглавных букв\n",
    "features = {\n",
    "    \"digits\": df[\"text_no_spaces\"].str.contains(r\"\\d\"),\n",
    "    \"latin\": df[\"text_no_spaces\"].str.contains(r\"[A-Za-z]\"),\n",
    "    \"uppercase\": df[\"text_no_spaces\"].str.contains(r\"[А-Я]\")\n",
    "}\n",
    "feature_df = pd.DataFrame(features).mean() * 100\n",
    "\n",
    "feature_df.plot(kind=\"bar\", color=\"#FDB29F\", edgecolor=\"black\")\n",
    "plt.title(\"Доля строк с особыми символами (%)\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8f4ef4-db99-4ba4-8573-52b044e15c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1000 lower + 5 other \n",
    "df[\"first_char\"] = df[\"text_no_spaces\"].str[0]\n",
    "df[\"first_char_type\"] = df[\"first_char\"].apply(\n",
    "    lambda x: \"digit\" if x.isdigit()\n",
    "    else \"upper\" if x.isupper()\n",
    "    else \"lower\" if x.islower()\n",
    "    else \"other\"\n",
    ")\n",
    "\n",
    "df[\"first_char_type\"].value_counts().plot(kind=\"bar\", color=\"#FDB29F\", edgecolor=\"black\")\n",
    "plt.title(\"Тип первого символа строки\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382ddc0-02fd-4f23-8948-583dd7bc4b30",
   "metadata": {},
   "source": [
    "**Основные функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d94f31-0c30-41ef-9f76-2a1f54fe7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Восстанавливает пробелы в строке по их индексам\n",
    "def indices_to_text(s_no: str, idxs: set[int]) -> str:\n",
    "    out = []\n",
    "    for i, ch in enumerate(s_no):\n",
    "        if i in idxs: out.append(' ')\n",
    "        out.append(ch)\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e62305-1664-4260-a552-98fa45093b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращает индексы пробелов в строке с пробелами, пересчитанные в координатах строки без пробелов\n",
    "def space_indices(s_spaced: str) -> list[int]:\n",
    "    idxs, pos = [], 0\n",
    "    for ch in s_spaced:\n",
    "        if ch == \" \":\n",
    "            idxs.append(pos)\n",
    "        else:\n",
    "            pos += 1\n",
    "    return idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a371c7e-1455-4e89-b656-c788555d21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вычисляет F1-score для двух множеств индексов\n",
    "def f1_sets(gold: set[int], pred: set[int]) -> float:\n",
    "    tp = len(gold & pred); fp = len(pred - gold); fn = len(gold - pred)\n",
    "    if tp == 0: return 0.0\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6829ad1f-544c-466f-9e06-fcea9df320bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Формирует файл для отправки (submission) на основе baseline-предсказаний\n",
    "def make_submission(baseline_path, out_path):\n",
    "    df = pd.read_csv(baseline_path)\n",
    "\n",
    "    df = df[[\"id\", \"indices\"]].rename(columns={\"indices\": \"predicted_positions\"})\n",
    "\n",
    "    df[\"predicted_positions\"] = df[\"predicted_positions\"].apply(\n",
    "        lambda x: x.replace(\" \", \"\") if isinstance(x, str) else str(x)\n",
    "    )\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Submission сохранён в {out_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a9b33-7aae-48af-a190-44b94ca3d753",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Лексические словари и эвристики\n",
    "\n",
    "Помимо модели, для восстановления пробелов полезно использовать заранее подготовленные **лексические словари**:\n",
    "- **Предлоги** (`PREPOSITIONS`) — помогают разделять устойчивые конструкции (\"вгороде\" → \"в городе\").\n",
    "- **Союзы** (`CONJUNCTIONS`) — сигнализируют о месте разрыва (\"ичтоб\" → \"и чтоб\").\n",
    "- **Местоимения** (`PRONOUNS`) \n",
    "- **Бренды / модели** (`BRANDS`) — важны для корректного выделения товарных наименований (\"куплюiphone14\" → \"куплю iphone 14\").\n",
    "- **Устойчивые фразы** (`COMMON_PHRASES`) — часто встречающиеся выражения (\"срочно продам\", \"в хорошем состоянии\").\n",
    "- **Специфичные для Авито слова** (`AVITO_WORDS`) — эвристики, выделенные из реальных данных (например, \"торг\", \"срочно\", \"доставка\").\n",
    "- **Типичные окончания** (`COMMON_ENDINGS`)\n",
    "\n",
    "\n",
    "Используются для:\n",
    "1. Для постобработки предсказаний модели (добавление пробелов вокруг найденных слов)\n",
    "2. Для генерации дополнительных признаков в ML-модели\n",
    "3. Для анализа покрытия датасета и выявления частых паттернов ошибок\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe76dceb-0fab-4161-8a48-f59c7613cccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['квартиру',\n",
       " 'телевизо',\n",
       " 'елевизор',\n",
       " 'куплютел',\n",
       " 'уплютеле',\n",
       " 'ищуработ',\n",
       " 'щуработу',\n",
       " 'репетито',\n",
       " 'ищурепет',\n",
       " 'щурепети',\n",
       " 'урепетит',\n",
       " 'епетитор',\n",
       " 'петитора',\n",
       " 'етиторап',\n",
       " 'титорапо',\n",
       " 'ищусобак',\n",
       " 'щусобаку',\n",
       " 'сдамквар',\n",
       " 'дамкварт',\n",
       " 'амкварти']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_common_phrases_no_spaces(texts, min_len=8, min_freq=3, topn=20):\n",
    "    substrs = Counter()\n",
    "    for t in texts:\n",
    "        for i in range(len(t) - min_len):\n",
    "            sub = t[i:i+min_len]\n",
    "            substrs[sub] += 1\n",
    "    return [s for s,c in substrs.most_common(topn) if c >= min_freq]\n",
    "extract_common_phrases_no_spaces(df[\"text_no_spaces\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b676170-4eda-4eb7-9dea-1ce7b9b654b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['изор',\n",
       " 'ищурепетит',\n",
       " 'сдамкварти',\n",
       " 'весна',\n",
       " 'куплютелев',\n",
       " 'сдамкомнат',\n",
       " 'срочно',\n",
       " 'сдаюкварти',\n",
       " 'новыйдиван',\n",
       " 'куплюноутб',\n",
       " 'ищуучителя',\n",
       " 'ищуквартир',\n",
       " 'ищумастера',\n",
       " 'куплювелос',\n",
       " 'доставка',\n",
       " 'сдамстудию',\n",
       " 'куплюайфон',\n",
       " 'куплюгитар',\n",
       " 'куплюдиван',\n",
       " 'куплю',\n",
       " 'новаякуртк',\n",
       " 'куплюхолод',\n",
       " 'новыйноутб',\n",
       " 'ищуработуп',\n",
       " 'куплютелеф',\n",
       " 'недорого',\n",
       " 'хочукупить',\n",
       " 'естьтолько',\n",
       " 'помню',\n",
       " 'пожелаймне',\n",
       " 'дорого',\n",
       " 'срочнопрод',\n",
       " 'новыйтелеф',\n",
       " 'ищукомнату',\n",
       " 'ипед',\n",
       " 'ильник',\n",
       " 'рочно',\n",
       " 'куплюкомпь',\n",
       " 'куплюпылес',\n",
       " 'куплюмикро',\n",
       " 'куплюдетск',\n",
       " 'белый',\n",
       " 'ский',\n",
       " 'гарантия',\n",
       " 'новый',\n",
       " 'центр',\n",
       " 'новыйхолод',\n",
       " 'чтоделать',\n",
       " 'продаю',\n",
       " 'хочузаказа']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Специфичные для Авито слова \n",
    "def extract_avito_words_no_spaces(texts, min_len=4, max_len=10, topn=50):\n",
    "    words = Counter()\n",
    "    for t in texts:\n",
    "        for w in re.findall(r\"[а-яА-ЯёЁ]{%d,%d}\" % (min_len, max_len), t):\n",
    "            words[w.lower()] += 1\n",
    "    return [w for w,_ in words.most_common(topn)]\n",
    "extract_avito_words_no_spaces(df[\"text_no_spaces\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6b4f7b-2c23-47ef-8cb2-c04dd063ad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acer',\n",
       " 'Adidas',\n",
       " 'Asus',\n",
       " 'AsusROG',\n",
       " 'Atlant',\n",
       " 'Avito',\n",
       " 'Bosch',\n",
       " 'Canon',\n",
       " 'Casio',\n",
       " 'Dell',\n",
       " 'Dyson',\n",
       " 'Fender',\n",
       " 'Giant',\n",
       " 'Gibson',\n",
       " 'HP',\n",
       " 'Honor',\n",
       " 'Huawei',\n",
       " 'IKEA',\n",
       " 'Ikea',\n",
       " 'Indesit']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример извлечения брендов по латинице\n",
    "brands_list = []\n",
    "for text in df[\"text_no_spaces\"]:\n",
    "    brands = re.findall(r\"[A-Za-z]{2,}\", text)\n",
    "    brands_list.extend(brands)\n",
    "\n",
    "brands_list = sorted(set(brands_list))\n",
    "brands_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09b5a2-805c-4aab-bec9-3773f07deb51",
   "metadata": {},
   "source": [
    "C помощью такого рода анализа можно эвристически восстановить словари для сегментации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070ba610-a7c0-4315-9630-2bec38a334cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANDS = [\n",
    "    \"Apple\", \"Samsung\", \"Xiaomi\", \"Huawei\", \"Honor\", \"Nokia\", \"Sony\",\n",
    "    \"LG\", \"HTC\", \"Motorola\", \"Realme\", \"OnePlus\", \"Oppo\", \"Meizu\",\n",
    "    \"Google\", \"Asus\", \"Lenovo\", \"Acer\", \"Dell\", \"HP\", \"MSI\", \"Razer\",\n",
    "    \"Microsoft\", \"Panasonic\", \"Philips\", \"Sharp\", \"Toshiba\", \"BlackBerry\",\n",
    "    \"Canon\", \"Nikon\", \"Fujifilm\", \"Olympus\", \"Leica\", \"GoPro\", \"DJI\", \n",
    "    \"Bosch\", \"Siemens\", \"Miele\", \"Electrolux\", \"Zanussi\", \"Indesit\",\n",
    "    \"Hotpoint\", \"Whirlpool\", \"Beko\", \"Gorenje\", \"Kuppersberg\", \"Haier\",\n",
    "    \"Yamaha\", \"Fender\", \"Gibson\", \"Ibanez\", \"Casio\", \"Roland\", \"Korg\",\n",
    "    \"Marshall\", \"Shure\", \"Sennheiser\", \"JBL\", \"Behringer\", \"AKG\",\n",
    "    \"BMW\", \"Mercedes\", \"Audi\", \"Volkswagen\", \"Skoda\", \"Porsche\",\n",
    "    \"Lexus\", \"Toyota\", \"Mazda\", \"Honda\", \"Mitsubishi\", \"Subaru\",\n",
    "    \"Suzuki\", \"Nissan\", \"Infiniti\", \"Acura\", \"Hyundai\", \"Kia\",\n",
    "    \"Peugeot\", \"Renault\", \"Citroen\", \"Opel\", \"Fiat\", \"Jeep\",\n",
    "    \"Chery\", \"Geely\", \"Lada\", \"UAZ\", \"Volvo\", \"Jaguar\", \"Land Rover\",\n",
    "    \"Nike\", \"Adidas\", \"Puma\", \"Reebok\", \"Under Armour\", \"New Balance\",\n",
    "    \"Columbia\", \"The North Face\", \"Patagonia\", \"Timberland\", \"Crocs\",\n",
    "    \"Converse\", \"Vans\", \"Levi's\", \"Wrangler\", \"Zara\", \"H&M\", \"Uniqlo\",\n",
    "    \"IKEA\", \"Hoff\", \"Leroy Merlin\", \"Castorama\", \"Decathlon\"\n",
    "]\n",
    "\n",
    "AVITO_WORDS = {\n",
    "    # Общие действия\n",
    "    \"куплю\", \"продам\", \"сдаю\", \"сдам\", \"ищу\", \"отдам\", \"даром\", \"срочно\", \"недорого\",\n",
    "    \"новый\", \"новая\", \"б/у\", \"бу\", \"работа\", \"удаленно\", \"доставка\", \"обмен\",\n",
    "\n",
    "    # Недвижимость\n",
    "    \"квартира\", \"квартиру\", \"комната\", \"комнату\", \"дом\", \"гараж\", \"дача\",\n",
    "    \"участок\", \"земля\", \"подмосковье\", \"метро\", \"центр\", \"район\", \"улица\", \"срок\",\n",
    "\n",
    "    # Мебель\n",
    "    \"диван\", \"шкаф\", \"стол\", \"кровать\", \"матрас\", \"кухня\", \"кухонный\", \"стул\",\n",
    "    \"комод\", \"тумба\", \"полка\", \"угловой\", \"раскладной\", \"стенка\", \"мебель\",\n",
    "\n",
    "    # Бытовая техника\n",
    "    \"техника\", \"холодильник\", \"морозильник\", \"стиральная\", \"стиральную\", \"машина\",\n",
    "    \"посудомоечная\", \"плита\", \"духовка\", \"микроволновка\", \"утюг\", \"чайник\",\n",
    "    \"пылесос\", \"кондиционер\", \"телевизор\", \"ноутбук\", \"монитор\", \"компьютер\",\n",
    "    \"принтер\", \"сканер\",\n",
    "\n",
    "    # Электроника и телефоны\n",
    "    \"айфон\", \"iphone\", \"смартфон\", \"телефон\", \"samsung\", \"xiaomi\", \"huawei\",\n",
    "    \"honor\", \"nokia\", \"sony\", \"philips\", \"lenovo\", \"asus\", \"acer\", \"hp\",\n",
    "    \"dell\", \"canon\", \"nikon\", \"fujifilm\", \"olympus\", \"gopro\", \"панасоник\",\n",
    "\n",
    "    # Музыкальные инструменты\n",
    "    \"гитара\", \"электрогитара\", \"бас\", \"пианино\", \"синтезатор\", \"барабан\", \"скрипка\",\n",
    "    \"репетитор\", \"уроки\", \"биология\", \"математика\", \"физика\", \"английский\", \"шкаф\"\n",
    "\n",
    "    # Транспорт\n",
    "    \"авто\", \"машина\", \"автомобиль\", \"мотоцикл\", \"скутер\", \"велосипед\", \"колеса\",\n",
    "    \"шины\", \"резина\", \"запчасти\", \"лада\", \"uaz\", \"toyota\", \"honda\", \"kia\",\n",
    "    \"hyundai\", \"bmw\", \"audi\", \"mercedes\", \"volkswagen\", \"skoda\", \"lexus\",\n",
    "\n",
    "    # Животные\n",
    "    \"кошка\", \"кот\", \"котенок\", \"собака\", \"щенок\", \"порода\", \"отдам\", \"даром\",\n",
    "    \"птица\", \"попугай\", \"хомяк\", \"кролик\", \"рыбка\", \"аквариум\",\n",
    "\n",
    "    # Услуги\n",
    "    \"грузчик\", \"переезд\", \"ремонт\", \"мастер\", \"строитель\", \"уборка\", \"услуги\",\n",
    "    \"подключ\", \"монтаж\", \"отделка\", \"дизайн\", \"строительство\",\"квартира\",\"квартиру\",\"квартир\",\"ремонт\",\"подключ\",\"ключ\",\"подмосковье\",\n",
    "  \"доставка\",\"недорого\",\"кошку\",\"ноутбук\",\"метро\",\"репетитор\",\"биологии\",\n",
    "  \"подработка\",\"вечерам\",\"комнату\",\"студентке\",\"собаку\",\"лабрадор\",\"диван\",\"удаленно\"\n",
    "}\n",
    "\n",
    "COMMON_PHRASES = {\"я не\", \"я уже не\", \"не хочу\", \"не могу\", \"не знаю\",\n",
    "    \"вы посмотрите\", \"как красиво\", \"бу\", \"под ключ\",\"для переезда\",\"в подмосковье\",\"с мебелью\",\"с техникой\",\"отдам даром\",\n",
    "    \"с мебелью\", \"с техникой\", \"с мебелью и техникой\", \"без мебели\",\n",
    "    \"без посредников\", \"на длительный срок\", \"посуточно\", \"в хорошем состоянии\",\n",
    "    \"в отличном состоянии\", \"рядом с метро\", \"до метро пешком\", \"в центре города\",\n",
    "    \"под ключ\", \"свежий ремонт\", \"евроремонт\", \"современный ремонт\",\n",
    "    \"срочная продажа\", \"срочно продам\", \"сдаю комнату\", \"сдаю квартиру\",\n",
    "    \"продаю дом\", \"продаю участок\", \"раскладной диван\", \"угловой диван\",\n",
    "    \"обеденный стол\", \"кухонный гарнитур\", \"шкаф купе\", \"компьютерный стол\",\n",
    "    \"двуспальная кровать\", \"односпальная кровать\", \"ортопедический матрас\",\n",
    "    \"новый диван\", \"б/у диван\", \"мебель на заказ\", \"стиральная машина\",\n",
    "    \"посудомоечная машина\", \"холодильник новый\", \"холодильник б/у\",\n",
    "    \"телевизор samsung\", \"телевизор lg\", \"ноутбук asus\", \"ноутбук lenovo\",\n",
    "    \"ноутбук hp\", \"ноутбук dell\", \"айфон 14 про\", \"айфон 13 про\",\n",
    "    \"айфон 12 про\", \"айфон 11 про\", \"айфон xr\", \"айфон se\",\n",
    "    \"микроволновая печь\", \"электрическая плита\", \"газовая плита\",\n",
    "    \"кондиционер новый\", \"кондиционер б/у\", \"срочная продажа авто\",\n",
    "    \"в хорошем состоянии\", \"отличное состояние\", \"на ходу\", \"не битый\",\n",
    "    \"без пробега\", \"пробег по россии\", \"зимняя резина\", \"летняя резина\",\n",
    "    \"новый аккумулятор\", \"гараж в собственности\", \"отдам даром\",\n",
    "    \"отдам котенка\", \"отдам щенка\", \"кошка даром\", \"собака даром\",\n",
    "    \"в добрые руки\", \"чистокровный щенок\", \"породистый кот\",\n",
    "    \"без документов\", \"с документами\", \"щенок мальчик\", \"щенок девочка\",\n",
    "    \"удаленная работа\", \"работа в москве\", \"работа в санкт петербурге\",\n",
    "    \"работа на дому\", \"частичная занятость\", \"полная занятость\",\n",
    "    \"подработка студентам\", \"услуги грузчиков\", \"услуги такси\",\n",
    "    \"услуги сантехника\", \"услуги электрика\", \"ремонт квартир\",\n",
    "    \"ремонт под ключ\", \"грузчики переезд\", \"перевозка мебели\",\n",
    "    \"вывоз мусора\", \"доставка на дом\", \"бесплатная доставка\", \"доставка\"\n",
    "}\n",
    "\n",
    "PREPOSITIONS = {\n",
    "    \"в\",\"на\",\"с\",\"к\",\"у\",\"по\",\"от\",\"до\",\"из\",\"без\",\"для\",\"при\",\"под\",\"над\",\"перед\",\"после\",\"между\",\"около\",\"за\",\"про\",\"об\",\"о\"\n",
    "}\n",
    "\n",
    "\n",
    "PRONOUNS = {\n",
    "    \"я\",\"ты\",\"он\",\"она\",\"оно\",\"мы\",\"вы\",\"они\",\n",
    "    \"мне\",\"ему\",\"ей\",\"нам\",\"вам\",\"их\",\"нас\",\n",
    "    \"мой\",\"моя\",\"моё\",\"мои\",\"твой\",\"твоя\",\"твоё\",\"твои\",\n",
    "    \"свой\",\"своя\",\"своё\",\"свои\",\"наш\",\"наша\",\"наше\",\"наши\",\n",
    "    \"ваш\",\"ваша\",\"ваше\",\"ваши\",\"этот\",\"эта\",\"это\",\"эти\",\n",
    "    \"тот\",\"та\",\"то\",\"те\",\"кто\",\"что\",\"какой\",\"какая\",\"какое\",\"какие\", \"не\", \"как\", \"уже\"\n",
    "}\n",
    "\n",
    "COMMON_ENDINGS = (\"а\",\"о\",\"е\",\"и\",\"ы\",\"ый\",\"ой\",\"ий\", \"ого\", \"ими\", \"ать\", \"ить\")\n",
    "\n",
    "COMMON_BIGRAMS = {\n",
    "    (\"дом\", \"в\"),\n",
    "    (\"я\", \"не\"),\n",
    "    (\"как\", \"красиво\"),\n",
    "    (\"с\", \"мебелью\"),\n",
    "    (\"с\", \"техникой\"),\n",
    "    (\"для\", \"переезда\"),\n",
    "    (\"отдам\", \"даром\"),\n",
    "    (\"куплю\", \"айфон\"),\n",
    "    (\"новый\", \"диван\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e713c09a-93a2-4849-aa6e-4f593dbad12f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Модель T5 (zero-shot) + эвристики + wordfreq + постобработка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ec558-1918-46e0-8da1-599346ba2019",
   "metadata": {},
   "source": [
    "Данный алгоритм комбинирует **генеративную модель T5** с набором эвристик и проверок, чтобы восстановление пробелов было более надёжным.\n",
    "\n",
    "1. Основная модель (T5)\n",
    "* Используем модель `ai-forever/ruT5-base` в режиме `text2text-generation`.\n",
    "\n",
    "2. Проверка качества результата\n",
    "\n",
    "После генерации T5 результат проходит жёсткую фильтрацию:\n",
    "\n",
    "* если модель **сильно сжала текст** (длина результата < длины исходного),\n",
    "* если **нет пробелов** (результат — одно слово),\n",
    "* если **мало уникальных слов** (например, только повтор «ни ни ни ни»),\n",
    "* если результат стал подозрительно **длинным** (более чем в 2 раза длиннее исходного),\n",
    "* если в начале текста идут **односимвольные токены** (мусор),\n",
    "* если слишком много слов с низкой частотой по `wordfreq` (нереальные слова),\n",
    "  → в таких случаях используем **fallback** — правило-базовую сегментацию (`heuristic_segment`).\n",
    "\n",
    " 3. Эвристическая сегментация (fallback)\n",
    "\n",
    "Если T5 «сломался», текст обрабатывается простыми правилами:\n",
    "\n",
    "* пробел перед/после цифр (`iphone14` → `iphone 14`),\n",
    "* пробел перед заглавной буквой (`PlayStation` → `Play Station`),\n",
    "* пробелы вокруг известных брендов (`куплюiphone` → `куплю iphone`).\n",
    "\n",
    "4. Разбиение длинных слов (wordfreq)\n",
    "\n",
    "Если в результате остались слишком длинные и редкие слова, они дополнительно сегментируются:\n",
    "\n",
    "* вставляем пробел после гласной перед согласной,\n",
    "* ориентируемся на частоты `zipf_frequency` (чем слово реальнее, тем выше вероятность оставить его целиком).\n",
    "\n",
    "5. Постобработка результата\n",
    "\n",
    "* **Удаление повторов**: подряд идущие одинаковые слова убираются.\n",
    "* **Фильтрация мусора**: односимвольные слова удаляются (кроме допустимых предлогов `в`, `с`, `к`, `и`, `а`, `о`).\n",
    "* **Очистка пробелов**: убираются лишние пробелы, нормализуется текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d5ea605-8674-4c0d-b470-3011ffd8322f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ai-forever/ruT5-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tok, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b1748aab-f754-41d0-aca5-5e78c14678bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "      <th>spaced_text</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "      <td>куплюайфон 14 про</td>\n",
       "      <td>[10, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "      <td>ищудомв Подмосковье</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "      <td>сдаю квартирусмебельюитехникой</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "      <td>но выйдивандоставканедорого</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "      <td>о тдамдаромкошку</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>работавМосквеудаленно</td>\n",
       "      <td>работав Мо сквеудаленно</td>\n",
       "      <td>[7, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>куплютелевизорPhilips</td>\n",
       "      <td>ку плютелевизор Philips</td>\n",
       "      <td>[2, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ищугрузчиковдляпереезда</td>\n",
       "      <td>и щугрузчиковдляпереезда</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ремонтквартирподключ</td>\n",
       "      <td>ре монтквартирподключ</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>куплюноутбукHP</td>\n",
       "      <td>ку плюноутбук</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 text_no_spaces                     spaced_text   indices\n",
       "0   0                куплюайфон14про               куплюайфон 14 про  [10, 12]\n",
       "1   1             ищудомвПодмосковье             ищудомв Подмосковье       [7]\n",
       "2   2  сдаюквартирусмебельюитехникой  сдаю квартирусмебельюитехникой       [4]\n",
       "3   3     новыйдивандоставканедорого     но выйдивандоставканедорого       [2]\n",
       "4   4                отдамдаромкошку                о тдамдаромкошку       [1]\n",
       "5   5          работавМосквеудаленно         работав Мо сквеудаленно    [7, 9]\n",
       "6   6          куплютелевизорPhilips         ку плютелевизор Philips   [2, 14]\n",
       "7   7        ищугрузчиковдляпереезда        и щугрузчиковдляпереезда       [1]\n",
       "8   8           ремонтквартирподключ           ре монтквартирподключ       [2]\n",
       "9   9                 куплюноутбукHP                   ку плюноутбук       [2]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BRAND_PATTERN = re.compile(r\"(\" + \"|\".join(BRANDS) + r\")\", re.IGNORECASE)\n",
    "\n",
    "def heuristic_segment(s: str) -> str:\n",
    "    \"\"\"Разделение по цифрам, заглавным и брендам\"\"\"\n",
    "    s = re.sub(r\"(?<=\\D)(\\d+)\", r\" \\1\", s)    \n",
    "    s = re.sub(r\"(\\d+)(?=\\D)\", r\"\\1 \", s)   \n",
    "    s = re.sub(r\"(?<!^)([А-ЯA-Z])\", r\" \\1\", s) \n",
    "    s = BRAND_PATTERN.sub(r\" \\1 \", s)          \n",
    "    return \" \".join(s.split())\n",
    "\n",
    "\n",
    "def refine_with_wordfreq(text: str, language=\"ru\") -> str:\n",
    "    \"\"\"\n",
    "    Доп. разбиение длинных склеек, если их частотность слишком низкая.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        if len(w) > 10 and zipf_frequency(w, language) < 1.5:\n",
    "            # очень редкое длинное слово то вставляем пробелы эвристически\n",
    "            w = re.sub(r\"([аеиоуыэюя])([бвгджзклмнпрстфхцчшщ])\", r\"\\1 \\2\", w, count=1)\n",
    "        new_words.append(w)\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "def validate_with_wordfreq(text, language=\"ru\", min_freq=1.5, threshold=0.5):\n",
    "    words = text.split()\n",
    "    low_freq_count = sum(zipf_frequency(w, language) < min_freq for w in words)\n",
    "    if words and low_freq_count / len(words) > threshold:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def batch_segment(texts: list[str]) -> list[str]:\n",
    "    outs = pipe(\n",
    "        texts,\n",
    "        max_new_tokens=64,\n",
    "        num_beams=1,\n",
    "        do_sample=False,\n",
    "        batch_size=8\n",
    "    )\n",
    "    results = []\n",
    "    for inp, o in zip(texts, outs):\n",
    "        gen = \" \".join(o[\"generated_text\"].split())\n",
    "\n",
    "        # Проверка адекватности\n",
    "        if (\n",
    "            len(gen) < len(inp)\n",
    "            or gen.count(\" \") < 1\n",
    "            or len(set(gen.split())) < 3\n",
    "            or any(len(w) == 1 for w in gen.split()[:5])  \n",
    "            or len(gen) > 2 * len(inp)\n",
    "            or not validate_with_wordfreq(gen)\n",
    "        ):\n",
    "            gen = heuristic_segment(inp)\n",
    "            \n",
    "\n",
    "        # Доп. постобработка wordfreq\n",
    "        gen = refine_with_wordfreq(gen)\n",
    "        # Финальная чистка\n",
    "        gen = clean_output(gen)\n",
    "\n",
    "        results.append(gen)\n",
    "    return results\n",
    "\n",
    "def clean_output(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Постобработка результата:\n",
    "    - убираем дубликаты подряд\n",
    "    - выбрасываем односимвольные \"мусорные\" слова, кроме допустимых предлогов/союзов\n",
    "    \"\"\"\n",
    "    ALLOWED_SHORT = {\"в\", \"с\", \"к\", \"и\", \"а\", \"о\"}\n",
    "    words = text.split()\n",
    "    out = []\n",
    "    for w in words:\n",
    "        if out and out[-1].lower() == w.lower():\n",
    "            continue  # удаляем подряд идущие повторы\n",
    "        if len(w) == 1 and w.lower() not in ALLOWED_SHORT:\n",
    "            continue  # убираем мусор\n",
    "        out.append(w)\n",
    "    return \" \".join(out)\n",
    "\n",
    "\n",
    "def process_with_t5(df, text_column=\"text_no_spaces\", batch_size=16):\n",
    "    results = []\n",
    "    for start in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[start:start+batch_size]\n",
    "        spaced_texts = batch_segment(batch[text_column].tolist())\n",
    "\n",
    "        for row, spaced in zip(batch.to_dict(\"records\"), spaced_texts):\n",
    "            idxs = space_indices(spaced)  \n",
    "            results.append({\n",
    "                \"id\": row[\"id\"],\n",
    "                \"text_no_spaces\": row[text_column],\n",
    "                \"spaced_text\": spaced,\n",
    "                \"indices\": json.dumps(idxs, ensure_ascii=False)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "submission_df = process_with_t5(df)\n",
    "\n",
    "submission_df.head(10) # плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c1d92-cb38-44e3-95ba-1efc70e6d5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406ed2f-1dcd-4166-9abf-e1f7aa8ff3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092e40c-1efe-49b9-a0e3-8c94a83886e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aed2f38e-3b39-4ca9-b882-bc5a251e5f8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Рекурсивная сегментация с wordfreq (F1 = 66.798%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927beeb8-5609-4fa4-a3c3-60c5ed0096c6",
   "metadata": {},
   "source": [
    "Алгоритм полностью основан на **правилах, словарях и частотности слов** = регулярные выражения + словари + Zipf-частотность.\n",
    "\n",
    "Работа идёт строго по шагам:\n",
    "1. Сначала защищаем устойчивые фразы (через PHRASE_MAP).\n",
    "2. Потом базовые правила (цифры, заглавные, бренды).\n",
    "3. Жёсткая нарезка по словарям предлогов/местоимений.\n",
    "4. Каждое длинное слово проверяется частотным словарём (zipf_frequency) и, если оно редкое, разбивается рекурсивно (smart_split).\n",
    "5. В конце чистим пунктуацию (fix_punctuation).\n",
    "\n",
    "**Устойчивые фразы**  \n",
    "- Используем карту (`PHRASE_MAP`) и регулярку (`PHRASE_REGEX`),  \n",
    "- заранее защищаем выражения вроде *«в хорошем состоянии»*, *«срочно продам»*.\n",
    "\n",
    "**Базовые эвристики**  \n",
    "- пробелы вокруг цифр: `iphone14` → `iphone 14`,  \n",
    "- пробел перед заглавными: `PlayStation` → `Play Station`,  \n",
    "- пробелы вокруг брендов: `samsunggalaxy` → `samsung galaxy`.\n",
    "\n",
    "**Жёсткая нарезка по словарям**  \n",
    "- Предлоги и местоимения (`в`, `на`, `по`, `он`, `она` …) всегда выделяются отдельно,  \n",
    "- но только если они не «вшиты» внутрь длинного слова.\n",
    "\n",
    "**Рекурсивная сегментация с wordfreq**  \n",
    "- Каждое длинное слово проверяется по частотному словарю Zipf.  \n",
    "- Если слово «нереальное» → пробуем разрезать его на части.  \n",
    "- Для каждой возможной точки разреза считаем:  \n",
    "  - частотность левой и правой частей,  \n",
    "  - бонус, если разрез после гласной и перед согласной.  \n",
    "- Алгоритм рекурсивный: можно разбивать до тех пор, пока не получаются частотные слова.  \n",
    "\n",
    "**Постобработка пунктуации**  \n",
    "- убираем пробелы перед запятыми и точками,  \n",
    "- добавляем пробелы после запятых и дефисов,  \n",
    "- нормализуем пробелы.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02927567-6ad4-4e4c-b8d5-52862944ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHRASE_MAP = {re.sub(r\"\\s+\", \"\", p): p for p in COMMON_PHRASES}\n",
    "PHRASE_REGEX = re.compile(\"|\".join(re.escape(k) for k in PHRASE_MAP.keys()), re.IGNORECASE)\n",
    "BRAND_PATTERN = re.compile(r\"(\" + \"|\".join(BRANDS) + r\")\", re.IGNORECASE)\n",
    "\n",
    "def heuristic_segment_basic(s: str) -> str:\n",
    "    s = re.sub(r\"(?<=\\D)(\\d+)\", r\" \\1\", s)     \n",
    "    s = re.sub(r\"(\\d+)(?=\\D)\", r\"\\1 \", s)      \n",
    "    s = re.sub(r\"(?<!^)([А-ЯA-Z])\", r\" \\1\", s) \n",
    "    s = BRAND_PATTERN.sub(r\" \\1 \", s)          \n",
    "    return \" \".join(s.split())                 \n",
    "\n",
    "\n",
    "def force_split_by_dictionary(s: str, min_freq=2.5) -> str:\n",
    "    \"\"\"\n",
    "    Вставляем пробелы вокруг предлогов/местоимений,\n",
    "    но режем только если не ломаем нормальные слова.\n",
    "    \"\"\"\n",
    "    all_words = sorted(PREPOSITIONS.union(PRONOUNS), key=len, reverse=True)\n",
    "\n",
    "    for w in all_words:\n",
    "        pattern = re.compile(rf\"(?i){w}\")\n",
    "        pos = 0\n",
    "        while True:\n",
    "            m = pattern.search(s, pos)\n",
    "            if not m:\n",
    "                break\n",
    "            start, end = m.span()\n",
    "\n",
    "            # соседние куски\n",
    "            left, right = s[:start].rstrip(), s[end:].lstrip()\n",
    "\n",
    "            # если вшито внутрь длинного слова то пропускаем\n",
    "            if left and left[-1].isalpha() and not left[-1].isspace():\n",
    "                pos = end\n",
    "                continue\n",
    "            if right and right[0].isalpha() and not right[0].isspace():\n",
    "                pos = end\n",
    "                continue\n",
    "\n",
    "            # проверка \"реальности\" w\n",
    "            wl = w.lower()\n",
    "            if (wl in AVITO_WORDS or wl in PREPOSITIONS or wl in PRONOUNS\n",
    "                or zipf_frequency(wl, \"ru\") >= min_freq):\n",
    "                s = s[:start] + \" \" + m.group(0) + \" \" + s[end:]\n",
    "                pos = start + len(w) + 2\n",
    "            else:\n",
    "                pos = end\n",
    "\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def is_real_word(word: str, min_freq=3.0) -> bool:\n",
    "    wl = word.lower()\n",
    "    return (wl in AVITO_WORDS) or (wl in PREPOSITIONS) or (wl in PRONOUNS) or (zipf_frequency(wl, \"ru\") >= min_freq)\n",
    "\n",
    "def smart_split(token: str, min_freq=3.0) -> list[str]:\n",
    "    wl = token.lower()\n",
    "\n",
    "    # Если короткое или уже нормальное не трогаем\n",
    "    if len(wl) <= 5 or is_real_word(token, min_freq) or wl.endswith(COMMON_ENDINGS):\n",
    "        return [token]\n",
    "\n",
    "    # Слишком длинные токены режем \n",
    "    if len(wl) > 12 and not is_real_word(token, min_freq):\n",
    "        mid = len(wl) // 2\n",
    "        return smart_split(wl[:mid], min_freq) + smart_split(wl[mid:], min_freq)\n",
    "\n",
    "    best_split = None\n",
    "    best_score = zipf_frequency(wl, \"ru\")\n",
    "\n",
    "    for i in range(2, len(token)-2):\n",
    "        left, right = token[:i], token[i:]\n",
    "        score = zipf_frequency(left, \"ru\") + zipf_frequency(right, \"ru\")\n",
    "\n",
    "        # Проверка биграмм\n",
    "        if (left, right) in COMMON_BIGRAMS:\n",
    "            best_split = (left, right)\n",
    "            break\n",
    "\n",
    "        if score > best_score:\n",
    "            best_split = (left, right)\n",
    "            best_score = score\n",
    "\n",
    "    if best_split:\n",
    "        left, right = best_split\n",
    "        return smart_split(left, min_freq) + smart_split(right, min_freq)\n",
    "\n",
    "    return [token]\n",
    "\n",
    "\n",
    "def fix_punctuation(spaced: str) -> str:\n",
    "    spaced = re.sub(r\"\\s+,\", \",\", spaced)\n",
    "    spaced = re.sub(r\",(?=\\S)\", \", \", spaced)\n",
    "    spaced = re.sub(r\"\\s*-\\s*\", \" - \", spaced)\n",
    "    spaced = re.sub(r\"\\s+([.!?;:])\", r\"\\1\", spaced)\n",
    "    spaced = re.sub(r\"\\s{2,}\", \" \", spaced)\n",
    "\n",
    "    return spaced.strip()\n",
    "\n",
    "def heuristic_segment(s: str) -> str:\n",
    "    # 1. Устойчивые фразы\n",
    "    s = PHRASE_REGEX.sub(lambda m: PHRASE_MAP.get(m.group(0).lower(), m.group(0)), s)\n",
    "    # 2. Базовые эвристики\n",
    "    s = heuristic_segment_basic(s)\n",
    "    # 3. Жёсткая нарезка по предлогам/местоимениям\n",
    "    s = force_split_by_dictionary(s)\n",
    "    # 4. Токенизация по пробелам и дефисам\n",
    "    tokens = re.split(r\"(\\s+|-)\", s)\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.strip() == \"\":\n",
    "            continue\n",
    "        if token == \"-\":\n",
    "            new_tokens.append(\"-\")\n",
    "            continue\n",
    "        new_tokens.extend(smart_split(token))\n",
    "\n",
    "    spaced = \" \".join(new_tokens)\n",
    "\n",
    "    return fix_punctuation(spaced)\n",
    "\n",
    "def run_baseline(csv_in, csv_out, save=True):\n",
    "    df = load_dataset_with_summary(csv_in)  # ожидаем id,text_no_spaces\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        s_no = str(row[\"text_no_spaces\"])\n",
    "        spaced = heuristic_segment(s_no)\n",
    "        idxs = space_indices(spaced)\n",
    "        results.append({\n",
    "            \"id\": row[\"id\"],\n",
    "            \"text_no_spaces\": s_no,\n",
    "            \"spaced_text\": spaced,\n",
    "            \"indices\": json.dumps(idxs, ensure_ascii=False)\n",
    "        })\n",
    "    out_df = pd.DataFrame(results)\n",
    "    if save:\n",
    "        out_df.to_csv(csv_out, index=False)\n",
    "        print(f\"Submission сохранён в {csv_out}\")\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c3250241-8b0f-4964-b58c-86a5ed12ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сводка по датасету\n",
      "Размер датасета: (1005, 3)\n",
      "Средняя длина: 22.860696517412936\n",
      "Мин длина: 4\n",
      "Макс длина: 56\n",
      "Строк с цифрами: 26\n",
      "Строк с заглавными буквами: 589\n",
      "Строк с латиницей: 90\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1005 entries, 0 to 1004\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              1005 non-null   int64 \n",
      " 1   text_no_spaces  1005 non-null   object\n",
      " 2   length          1005 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 23.7+ KB\n",
      "None\n",
      "Submission сохранён в avito_baseline_wordfreq.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "      <th>spaced_text</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "      <td>куплю айфон 14 про</td>\n",
       "      <td>[5, 10, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "      <td>ищу домв подмосковье</td>\n",
       "      <td>[3, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "      <td>сдаю кварти рус мебелью и техникой</td>\n",
       "      <td>[4, 10, 13, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "      <td>новый дивандоставканедорого</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "      <td>отдам даром кошку</td>\n",
       "      <td>[5, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>работавМосквеудаленно</td>\n",
       "      <td>работа в москвеудаленно</td>\n",
       "      <td>[6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>куплютелевизорPhilips</td>\n",
       "      <td>куплюте леви зор Philips</td>\n",
       "      <td>[7, 11, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ищугрузчиковдляпереезда</td>\n",
       "      <td>ищу груз чиков для переезда</td>\n",
       "      <td>[3, 7, 12, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ремонтквартирподключ</td>\n",
       "      <td>ремонт квартир под ключ</td>\n",
       "      <td>[6, 13, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>куплюноутбукHP</td>\n",
       "      <td>куплю ноутбук hp</td>\n",
       "      <td>[5, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ищуквартирууметро</td>\n",
       "      <td>ищуквартирууметро</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>новаямикроволновкаSamsung</td>\n",
       "      <td>новаямикроволновка Samsung</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>срочнопродамвелосипед</td>\n",
       "      <td>срочно про дамв ел оси пед</td>\n",
       "      <td>[6, 9, 13, 15, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>куплюгитаруFender</td>\n",
       "      <td>куплю гитару Fen der</td>\n",
       "      <td>[5, 11, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ищурепетиторапобиологии</td>\n",
       "      <td>ищурепетиторапобиологии</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>сдаюгаражнадлительныйсрок</td>\n",
       "      <td>сдаюгаражна длительный срок</td>\n",
       "      <td>[11, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>куплюдиванбу</td>\n",
       "      <td>куплю дива нбу</td>\n",
       "      <td>[5, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>ищумастерапоремонтухолодильников</td>\n",
       "      <td>ищумастерапоремо нту холод иль ников</td>\n",
       "      <td>[16, 19, 24, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>новыйшкафдоставкасегодня</td>\n",
       "      <td>но вы йшкаф дос тавка сегодня</td>\n",
       "      <td>[2, 4, 9, 12, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>куплюXboxOne</td>\n",
       "      <td>куплю Xbox One</td>\n",
       "      <td>[5, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                    text_no_spaces  \\\n",
       "0    0                   куплюайфон14про   \n",
       "1    1                ищудомвПодмосковье   \n",
       "2    2     сдаюквартирусмебельюитехникой   \n",
       "3    3        новыйдивандоставканедорого   \n",
       "4    4                   отдамдаромкошку   \n",
       "5    5             работавМосквеудаленно   \n",
       "6    6             куплютелевизорPhilips   \n",
       "7    7           ищугрузчиковдляпереезда   \n",
       "8    8              ремонтквартирподключ   \n",
       "9    9                    куплюноутбукHP   \n",
       "10  10                 ищуквартирууметро   \n",
       "11  11         новаямикроволновкаSamsung   \n",
       "12  12             срочнопродамвелосипед   \n",
       "13  13                 куплюгитаруFender   \n",
       "14  14           ищурепетиторапобиологии   \n",
       "15  15         сдаюгаражнадлительныйсрок   \n",
       "16  16                      куплюдиванбу   \n",
       "17  17  ищумастерапоремонтухолодильников   \n",
       "18  18          новыйшкафдоставкасегодня   \n",
       "19  19                      куплюXboxOne   \n",
       "\n",
       "                             spaced_text              indices  \n",
       "0                     куплю айфон 14 про          [5, 10, 12]  \n",
       "1                   ищу домв подмосковье               [3, 7]  \n",
       "2     сдаю кварти рус мебелью и техникой  [4, 10, 13, 20, 21]  \n",
       "3            новый дивандоставканедорого                  [5]  \n",
       "4                      отдам даром кошку              [5, 10]  \n",
       "5                работа в москвеудаленно               [6, 7]  \n",
       "6               куплюте леви зор Philips          [7, 11, 14]  \n",
       "7            ищу груз чиков для переезда       [3, 7, 12, 15]  \n",
       "8                ремонт квартир под ключ          [6, 13, 16]  \n",
       "9                       куплю ноутбук hp              [5, 12]  \n",
       "10                     ищуквартирууметро                   []  \n",
       "11            новаямикроволновка Samsung                 [18]  \n",
       "12            срочно про дамв ел оси пед   [6, 9, 13, 15, 18]  \n",
       "13                  куплю гитару Fen der          [5, 11, 14]  \n",
       "14               ищурепетиторапобиологии                   []  \n",
       "15           сдаюгаражна длительный срок             [11, 21]  \n",
       "16                        куплю дива нбу               [5, 9]  \n",
       "17  ищумастерапоремо нту холод иль ников     [16, 19, 24, 27]  \n",
       "18         но вы йшкаф дос тавка сегодня    [2, 4, 9, 12, 17]  \n",
       "19                        куплю Xbox One               [5, 9]  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_baseline(\"Downloads/dataset_1937770_3.txt\", \"avito_baseline_wordfreq.csv\")\n",
    "\n",
    "pd.read_csv(\"avito_baseline_wordfreq.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "440b60d5-ed40-4fed-bbea-3ca81d85a30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission сохранён в submission_2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[5,10,12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[3,7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[4,10,13,20,21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[5,10]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id predicted_positions\n",
       "0   0           [5,10,12]\n",
       "1   1               [3,7]\n",
       "2   2     [4,10,13,20,21]\n",
       "3   3                 [5]\n",
       "4   4              [5,10]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your Mean F1 = 66.798% submission_1\n",
    "submission = make_submission(\"avito_baseline_wordfreq.csv\", \"submission_2.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c902c20-fbb6-4890-b856-d4b84f11b982",
   "metadata": {},
   "source": [
    "## T5 — fine-tuning: Heuristic + Viterbi + wordfreq (F1 = 87.46%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba9e97-233b-4257-8142-5b2a7be8f0f1",
   "metadata": {},
   "source": [
    "Алгоритм объединяет **правила, словари и частотный словарь wordfreq** с динамическим программированием (Viterbi).  \n",
    "Ниже приведены основные этапы работы.\n",
    "\n",
    "1. Обработка устойчивых фраз (`PHRASE_MAP`, `PHRASE_REGEX`)\n",
    "- Фразы вроде **«в хорошем состоянии»**, **«срочно продам»** остаются целиком.  \n",
    "- Это защищает их от ошибочного разбиения.\n",
    "\n",
    "2. Базовые эвристики (`heuristic_segment_basic`)\n",
    "- Вставка пробелов **перед/после цифр**:  \n",
    "  `iphone14` → `iphone 14`.  \n",
    "- Пробел **перед заглавными буквами**:  \n",
    "  `PlayStation` → `Play Station`.\n",
    "\n",
    "3. Viterbi-сегментация (`segment_alpha_chunk`)\n",
    "- Применяется только к кириллическим кускам строки.  \n",
    "- Алгоритм динамического программирования:\n",
    "  - разбивает строку на слова,  \n",
    "  - минимизирует *«стоимость слова»* (`word_cost`),  \n",
    "  - учитывает частотность (`wordfreq`) и словари (**PREPOSITIONS, PRONOUNS, AVITO_WORDS, BRANDS**).  \n",
    "- Даёт **глобально оптимальное разбиение**, а не только локальные правила.\n",
    "\n",
    "4. Исправления после Viterbi\n",
    "- **`fix_oversegmentation`** — склеивает слишком короткие токены, если они не являются «реальными словами».  \n",
    "- **`fix_bigrams`** — если перед словом стоит триггер (*«куплю», «ищу», «сдаю»*), объединяет его с соседним.  \n",
    "- **`fix_suffix_splits`** — если алгоритм отрезал окончания (*«книг а»*), склеивает их обратно.  \n",
    "- **`fix_brands`** — восстанавливает бренды в верхнем регистре (*hp → HP, lg → LG*).\n",
    "\n",
    "5. Постобработка пунктуации (`fix_punctuation`)\n",
    "- Убирает пробелы **перед запятыми и точками**.  \n",
    "- Добавляет пробелы **после запятых и дефисов**.  \n",
    "- Исправляет частый паттерн **«б/у»**.\n",
    "\n",
    "6. Финальный результат\n",
    "- Итог всегда — строка с **нормализованными пробелами**.  \n",
    "- В `run_baseline` дополнительно считаются индексы пробелов (`space_indices`) → данные готовы для сабмита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2956835-4a38-4166-9f1d-d2565663b5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сводка по датасету\n",
      "Размер датасета: (1005, 3)\n",
      "Средняя длина: 22.860696517412936\n",
      "Мин длина: 4\n",
      "Макс длина: 56\n",
      "Строк с цифрами: 26\n",
      "Строк с заглавными буквами: 589\n",
      "Строк с латиницей: 90\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1005 entries, 0 to 1004\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              1005 non-null   int64 \n",
      " 1   text_no_spaces  1005 non-null   object\n",
      " 2   length          1005 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 23.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "      <th>spaced_text</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "      <td>куплю айфон 14 про</td>\n",
       "      <td>[5, 10, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "      <td>ищу дом в подмосковье</td>\n",
       "      <td>[3, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "      <td>сдаю квартиру с мебе льюи техникой</td>\n",
       "      <td>[4, 12, 13, 17, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "      <td>новый диван доставка недорого</td>\n",
       "      <td>[5, 10, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "      <td>отдам даром кошку</td>\n",
       "      <td>[5, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>работавМосквеудаленно</td>\n",
       "      <td>работа в москве удаленно</td>\n",
       "      <td>[6, 7, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>куплютелевизорPhilips</td>\n",
       "      <td>куплю телевизор Philips</td>\n",
       "      <td>[5, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ищугрузчиковдляпереезда</td>\n",
       "      <td>ищу грузчик о в для переезда</td>\n",
       "      <td>[3, 10, 11, 12, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ремонтквартирподключ</td>\n",
       "      <td>ремонт квартир под ключ</td>\n",
       "      <td>[6, 13, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>куплюноутбукHP</td>\n",
       "      <td>куплю ноутбук HP</td>\n",
       "      <td>[5, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ищуквартирууметро</td>\n",
       "      <td>ищу квартиру у метро</td>\n",
       "      <td>[3, 11, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>новаямикроволновкаSamsung</td>\n",
       "      <td>новая микроволновка Samsung</td>\n",
       "      <td>[5, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>срочнопродамвелосипед</td>\n",
       "      <td>срочно продам велосипед</td>\n",
       "      <td>[6, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>куплюгитаруFender</td>\n",
       "      <td>куплю гитару Fender</td>\n",
       "      <td>[5, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ищурепетиторапобиологии</td>\n",
       "      <td>ищу репетитора по биологии</td>\n",
       "      <td>[3, 13, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>сдаюгаражнадлительныйсрок</td>\n",
       "      <td>сдаю гараж на длительный срок</td>\n",
       "      <td>[4, 9, 11, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>куплюдиванбу</td>\n",
       "      <td>куплю диван б/у</td>\n",
       "      <td>[5, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>ищумастерапоремонтухолодильников</td>\n",
       "      <td>ищу мастера по ремонт у холодильник о в</td>\n",
       "      <td>[3, 10, 12, 18, 19, 30, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>новыйшкафдоставкасегодня</td>\n",
       "      <td>новый шкаф доставка сегодня</td>\n",
       "      <td>[5, 9, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>куплюXboxOne</td>\n",
       "      <td>куплю Xbox One</td>\n",
       "      <td>[5, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                    text_no_spaces  \\\n",
       "0    0                   куплюайфон14про   \n",
       "1    1                ищудомвПодмосковье   \n",
       "2    2     сдаюквартирусмебельюитехникой   \n",
       "3    3        новыйдивандоставканедорого   \n",
       "4    4                   отдамдаромкошку   \n",
       "5    5             работавМосквеудаленно   \n",
       "6    6             куплютелевизорPhilips   \n",
       "7    7           ищугрузчиковдляпереезда   \n",
       "8    8              ремонтквартирподключ   \n",
       "9    9                    куплюноутбукHP   \n",
       "10  10                 ищуквартирууметро   \n",
       "11  11         новаямикроволновкаSamsung   \n",
       "12  12             срочнопродамвелосипед   \n",
       "13  13                 куплюгитаруFender   \n",
       "14  14           ищурепетиторапобиологии   \n",
       "15  15         сдаюгаражнадлительныйсрок   \n",
       "16  16                      куплюдиванбу   \n",
       "17  17  ищумастерапоремонтухолодильников   \n",
       "18  18          новыйшкафдоставкасегодня   \n",
       "19  19                      куплюXboxOne   \n",
       "\n",
       "                                spaced_text                      indices  \n",
       "0                        куплю айфон 14 про                  [5, 10, 12]  \n",
       "1                     ищу дом в подмосковье                    [3, 6, 7]  \n",
       "2        сдаю квартиру с мебе льюи техникой          [4, 12, 13, 17, 21]  \n",
       "3             новый диван доставка недорого                  [5, 10, 18]  \n",
       "4                         отдам даром кошку                      [5, 10]  \n",
       "5                  работа в москве удаленно                   [6, 7, 13]  \n",
       "6                   куплю телевизор Philips                      [5, 14]  \n",
       "7              ищу грузчик о в для переезда          [3, 10, 11, 12, 15]  \n",
       "8                   ремонт квартир под ключ                  [6, 13, 16]  \n",
       "9                          куплю ноутбук HP                      [5, 12]  \n",
       "10                     ищу квартиру у метро                  [3, 11, 12]  \n",
       "11              новая микроволновка Samsung                      [5, 18]  \n",
       "12                  срочно продам велосипед                      [6, 12]  \n",
       "13                      куплю гитару Fender                      [5, 11]  \n",
       "14               ищу репетитора по биологии                  [3, 13, 15]  \n",
       "15            сдаю гараж на длительный срок               [4, 9, 11, 21]  \n",
       "16                          куплю диван б/у                      [5, 10]  \n",
       "17  ищу мастера по ремонт у холодильник о в  [3, 10, 12, 18, 19, 30, 31]  \n",
       "18              новый шкаф доставка сегодня                   [5, 9, 17]  \n",
       "19                           куплю Xbox One                       [5, 9]  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PHRASE_MAP = {re.sub(r\"\\s+\", \"\", p): p for p in COMMON_PHRASES}\n",
    "PHRASE_REGEX = re.compile(\"|\".join(map(re.escape, PHRASE_MAP.keys())), re.IGNORECASE)\n",
    "\n",
    "RU_CHUNK = re.compile(r\"[А-Яа-яЁё]+\")\n",
    "MIX_TOKENIZER = re.compile(r\"[А-Яа-яЁё]+|[A-Za-z]+|\\d+|[^\\w\\s]\")\n",
    "\n",
    "SUF1 = {\"у\",\"а\",\"о\",\"е\",\"ы\",\"и\",\"ю\",\"я\"}\n",
    "SUF2 = {\"ов\",\"ев\",\"ой\",\"ей\",\"ий\",\"ый\",\"ая\",\"яя\",\"ью\"}\n",
    "\n",
    "\n",
    "def fix_suffix_splits(spaced: str) -> str:\n",
    "    toks = spaced.split()\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(toks):\n",
    "        if i+1 < len(toks):\n",
    "            suf = toks[i+1].lower()\n",
    "            next_is_end = (i+2 == len(toks)) or re.fullmatch(r\"[,.!?;:-]\", toks[i+2])\n",
    "            if (suf in SUF1 or suf in SUF2) and next_is_end:\n",
    "                out.append(toks[i] + toks[i+1])\n",
    "                i += 2\n",
    "                continue\n",
    "        out.append(toks[i]); i += 1\n",
    "    return \" \".join(out)\n",
    "    \n",
    "def is_real_word(word: str, min_freq=2.5) -> bool:\n",
    "    wl = word.lower()\n",
    "    return (\n",
    "        wl in AVITO_WORDS\n",
    "        or wl in PREPOSITIONS\n",
    "        or wl in PRONOUNS\n",
    "        or wl in BRANDS\n",
    "        or zipf_frequency(wl, \"ru\") >= min_freq\n",
    "    )\n",
    "\n",
    "def word_cost(word: str) -> float:\n",
    "    wl = word.lower()\n",
    "\n",
    "    if wl in PREPOSITIONS or wl in PRONOUNS:\n",
    "        return 0.2\n",
    "    if wl in AVITO_WORDS or wl in BRANDS:\n",
    "        return 0.3\n",
    "    if len(wl) == 1:\n",
    "        return 50.0\n",
    "    if len(wl) == 2 and wl not in PREPOSITIONS and wl not in PRONOUNS:\n",
    "        return 25.0\n",
    "    if len(wl) <= 3:\n",
    "        return 15.0\n",
    "\n",
    "    z = zipf_frequency(wl, \"ru\")\n",
    "    if z <= 0:\n",
    "        return 8.0 + 0.3 * len(wl)\n",
    "    return (5.0 - z) + max(0, 0.2 * (len(wl) - 6))\n",
    "\n",
    "\n",
    "BRAND_UPPER = {\"hp\":\"HP\",\"ibm\":\"IBM\",\"lg\":\"LG\"}\n",
    "def fix_brands(spaced: str) -> str:\n",
    "    return re.sub(r\"\\b(hp|ibm|lg)\\b\", lambda m: BRAND_UPPER[m.group(1)], spaced, flags=re.I)\n",
    "\n",
    "\n",
    "BIGRAM_TRIGGERS = {\"ищу\", \"куплю\", \"сдаю\", \"работа\"}\n",
    "\n",
    "def fix_bigrams(tokens: list[str]) -> list[str]:\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i > 0 and tokens[i-1].lower() in BIGRAM_TRIGGERS and len(tokens[i]) > 2:\n",
    "            # объединяем с предыдущим\n",
    "            out[-1] = out[-1] + \" \" + tokens[i]\n",
    "        else:\n",
    "            out.append(tokens[i])\n",
    "        i += 1\n",
    "    return out\n",
    "\n",
    "\n",
    "def segment_alpha_chunk(chunk: str) -> list[str]:\n",
    "    wl = chunk.lower()\n",
    "\n",
    "    if len(chunk) >= 7 and is_real_word(chunk):\n",
    "        return [chunk]\n",
    "\n",
    "    n = len(chunk)\n",
    "    best = [0] + [1e9] * n\n",
    "    back = [-1] * (n + 1)\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(max(0, i - 15), i):\n",
    "            word = chunk[j:i]\n",
    "            wlow = word.lower()\n",
    "            \n",
    "            if len(wlow) == 1 and wlow not in PREPOSITIONS and wlow not in PRONOUNS:\n",
    "                continue\n",
    "            if len(wlow) == 2 and not is_real_word(wlow):\n",
    "                continue\n",
    "                \n",
    "            cost = best[j] + word_cost(word) + (0.5 if len(word) < 4 else 0)\n",
    "\n",
    "            if cost < best[i]:\n",
    "                best[i] = cost\n",
    "                back[i] = j\n",
    "    out = []\n",
    "    i = n\n",
    "    while i > 0:\n",
    "        j = back[i]\n",
    "        if j == -1:\n",
    "            return [chunk]\n",
    "        out.append(chunk[j:i])\n",
    "        i = j\n",
    "    return list(reversed(out))\n",
    "\n",
    "\n",
    "\n",
    "def fix_oversegmentation(tokens):\n",
    "    out, buf = [], []\n",
    "    for t in tokens:\n",
    "        if len(t) <= 2 and not is_real_word(t):\n",
    "            buf.append(t)\n",
    "        else:\n",
    "            if buf:\n",
    "                out.append(\"\".join(buf))\n",
    "                buf.clear()\n",
    "            out.append(t)\n",
    "    if buf:\n",
    "        out.append(\"\".join(buf))\n",
    "    return out\n",
    "\n",
    "\n",
    "def heuristic_segment_basic(s: str) -> str:\n",
    "    s = re.sub(r\"(?<=\\D)(\\d+)\", r\" \\1\", s)        \n",
    "    s = re.sub(r\"(\\d+)(?=\\D)\", r\"\\1 \", s)    \n",
    "    s = re.sub(r\"(?<!^)([А-ЯA-Z])\", r\" \\1\", s)   \n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def heuristic_segment(s: str) -> str:\n",
    "    s = PHRASE_REGEX.sub(lambda m: PHRASE_MAP.get(m.group(0).lower(), m.group(0)), s)\n",
    "\n",
    "    s = heuristic_segment_basic(s)\n",
    "\n",
    "    out = []\n",
    "    for tok in MIX_TOKENIZER.findall(s):\n",
    "        if RU_CHUNK.fullmatch(tok):\n",
    "            seg = segment_alpha_chunk(tok)\n",
    "            seg = fix_oversegmentation(seg)\n",
    "            seg = fix_bigrams(seg)\n",
    "\n",
    "            out.extend(seg)\n",
    "        else:\n",
    "            out.append(tok)\n",
    "\n",
    "    spaced = \" \".join(out)\n",
    "    spaced = fix_suffix_splits(spaced) \n",
    "    spaced = fix_punctuation(spaced)\n",
    "    spaced = fix_brands(spaced)\n",
    "\n",
    "    spaced = re.sub(r\"\\s+,\", \",\", spaced)\n",
    "    spaced = re.sub(r\",(?=\\S)\", \", \", spaced)\n",
    "    spaced = re.sub(r\"\\s*-\\s*\", \" - \", spaced)\n",
    "    spaced = re.sub(r\"\\s+([.!?;:])\", r\"\\1\", spaced)\n",
    "    spaced = re.sub(r\"\\s{2,}\", \" \", spaced)\n",
    "    spaced = re.sub(r\"\\bб[\\/\\\\]?\\s*у\\b\", \"б/у\", spaced, flags=re.I)\n",
    "    return spaced.strip()\n",
    "\n",
    "def run_baseline(csv_in, csv_out):\n",
    "    df = load_dataset_with_summary(csv_in)  # ожидаем id,text_no_spaces\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        s_no = str(row[\"text_no_spaces\"])\n",
    "        spaced = heuristic_segment(s_no)\n",
    "        idxs = space_indices(spaced)\n",
    "        results.append({\n",
    "            \"id\": row[\"id\"],\n",
    "            \"text_no_spaces\": s_no,\n",
    "            \"spaced_text\": spaced,\n",
    "            \"indices\": json.dumps(idxs, ensure_ascii=False)\n",
    "        })\n",
    "    out_df = pd.DataFrame(results)\n",
    "    out_df.to_csv(csv_out, index=False)\n",
    "\n",
    "run_baseline(\"Downloads/dataset_1937770_3.txt\", \"avito_baseline_wordfreq_3.csv\")\n",
    "\n",
    "pd.read_csv(\"avito_baseline_wordfreq_3.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9cb8e66-79a5-4745-bcd2-2d787f779690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission сохранён в submission_3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[5,10,12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[3,6,7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[4,12,13,17,21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[5,10,18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[5,10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>[1,3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>[5,6,7,10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>[5,6,11,13,19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>[5,6,8,19,22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>[5,6,12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id predicted_positions\n",
       "0        0           [5,10,12]\n",
       "1        1             [3,6,7]\n",
       "2        2     [4,12,13,17,21]\n",
       "3        3           [5,10,18]\n",
       "4        4              [5,10]\n",
       "...    ...                 ...\n",
       "1000  1000               [1,3]\n",
       "1001  1001          [5,6,7,10]\n",
       "1002  1002      [5,6,11,13,19]\n",
       "1003  1003       [5,6,8,19,22]\n",
       "1004  1004            [5,6,12]\n",
       "\n",
       "[1005 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your Mean F1 = 87.46%\n",
    "make_submission(\"avito_baseline_wordfreq_3.csv\", \"submission_3.csv\")\n",
    "pd.read_csv(\"submission_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530a25f-37f5-4c7d-939e-adec0dcc121d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Динамическое программирование + словарь + вероятностная модель (unigram) - ДОДЕЛАТЬ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c41ca3-df88-45a4-a551-7629ee531518",
   "metadata": {},
   "source": [
    "Этот метод объединяет:\n",
    "- **динамическое программирование** (оптимальное разбиение строки),\n",
    "- **лексические словари** (бренды, предлоги, авито-слова),\n",
    "- **вероятностную модель (unigram)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16a7b784-0b3b-4fbb-907e-b10f4a7b7338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                 text_no_spaces                      text_with_spaces\n",
      "0   0                куплюайфон14про                     к уплюайфон14пр о\n",
      "1   1             ищудомвПодмосковье              ищудомвподм о с к о в ье\n",
      "2   2  сдаюквартирусмебельюитехникой  с даю к в артирусмебельюитехни к о й\n",
      "3   3     новыйдивандоставканедорого        новыйдиван до с тавканедорог о\n",
      "4   4                отдамдаромкошку                      о тдамдаромкошку\n",
      "5   5          работавМосквеудаленно           работавм о с к в еудаленн о\n",
      "6   6          куплютелевизорPhilips            к уплютеле в из о рphilips\n",
      "7   7        ищугрузчиковдляпереезда           ищугрузчи к о в дляпереезда\n",
      "8   8           ремонтквартирподключ                  ремонтквартирподключ\n",
      "9   9                 куплюноутбукHP                       к уплюноутбукhp\n"
     ]
    }
   ],
   "source": [
    "# ДОДЕЛАТЬ\n",
    "\n",
    "def build_unigram_model(texts):\n",
    "    words = []\n",
    "    for t in texts:\n",
    "        words.extend(t.split())\n",
    "    counts = Counter(words)\n",
    "    total = sum(counts.values())\n",
    "    unigram_probs = {w: math.log(c / total) for w, c in counts.items()}\n",
    "    return unigram_probs\n",
    "\n",
    "\n",
    "def dp_segment(text, unigram_probs, lexicon, max_word_len=20):\n",
    "    n = len(text)\n",
    "    dp = [(-float(\"inf\"), []) for _ in range(n + 1)]\n",
    "    dp[0] = (0, [])\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        best_score, best_seg = -float(\"inf\"), None\n",
    "\n",
    "        for j in range(max(0, i - max_word_len), i):\n",
    "            word = text[j:i].lower()\n",
    "\n",
    "            # словарь даёт бонус\n",
    "            if word in lexicon:\n",
    "                score = dp[j][0] + 5.0\n",
    "            else:\n",
    "                score = dp[j][0] + unigram_probs.get(word, -10.0)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_seg = dp[j][1] + [word]\n",
    "\n",
    "        dp[i] = (best_score, best_seg)\n",
    "\n",
    "    return \" \".join(dp[n][1])\n",
    "\n",
    "\n",
    "PREPOSITIONS = {\"в\", \"на\", \"с\", \"по\", \"к\", \"о\", \"об\", \"за\", \"до\", \"из\", \"от\"}\n",
    "COMMON_PHRASES = {\"в хорошем состоянии\", \"срочно продам\", \"почти новый\"}\n",
    "AVITO_WORDS = {\"авито\", \"доставка\", \"торг\", \"срочно\"}\n",
    "BRANDS_LIST = {\"iphone\", \"samsung\", \"playstation\", \"nike\", \"adidas\", \"merida\"}\n",
    "\n",
    "LEXICON = PREPOSITIONS | AVITO_WORDS | BRANDS_LIST\n",
    "\n",
    "\n",
    "def process_df_with_dp(df, lexicon):\n",
    "    # строим униграммы на корпусе (пока из text_no_spaces после базовых эвристик)\n",
    "    unigram_model = build_unigram_model(df[\"text_no_spaces\"])\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        restored = dp_segment(row[\"text_no_spaces\"], unigram_model, lexicon)\n",
    "        results.append(restored)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"text_with_spaces\"] = results\n",
    "    return df\n",
    "\n",
    "\n",
    "result_df = process_df_with_dp(df, LEXICON)\n",
    "\n",
    "print(result_df.head(10)[[\"id\", \"text_no_spaces\", \"text_with_spaces\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea0b7e-4990-4812-a8ef-ef9cac8b81d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "173a079f-7a0f-4e46-aab4-cad830eacbf8",
   "metadata": {},
   "source": [
    "## Transformer+CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5441c-67d3-4a21-94de-fc6058f35bd4",
   "metadata": {},
   "source": [
    "**Модель сегментации**  \n",
    "   - Используем **TransformerEncoder** на уровне символов:\n",
    "     - Embedding-слой для символов.  \n",
    "     - Encoder с `d_model`, `nhead`, `num_layers`, `dropout`.  \n",
    "     - Linear-классификатор с двумя классами: *пробел / нет пробела*.  \n",
    "   - Потери считаем через **CrossEntropyLoss** с балансировкой классов (больший вес классу \"пробел\").\n",
    "\n",
    "**Обучение в два этапа (двухэтажное обучение)**  \n",
    "   - **Stage 1 (pretrain):** на синтетических данных (20k+) + небольшой части реальных.  \n",
    "   - **Stage 2 (finetune):** дообучение на реальных данных (размеченных ~1000).  \n",
    "   - Оптимизатор Adam, ранняя остановка по F1-score на валидации.  \n",
    "\n",
    " **Постобработка (эвристики + словари)**  \n",
    "   После модели к предсказаниям применяются корректировки:\n",
    "   - **Фиксируем суффиксы** (`-ой`, `-ий`, `-ая`) — не отделяем от основы.  \n",
    "   - **Короткие токены** (≤2 символов, если не предлоги/местоимения) склеиваем с соседними словами.  \n",
    "   - **Биграммы-триггеры** (`куплю`, `ищу`, `сдаю`, `работа`) склеиваются со следующим словом.  \n",
    "   - **Нормализация брендов** (`hp → HP`, `lg → LG`, `philips → Philips`).  \n",
    "   - **Устойчивые фразы** (из словаря `COMMON_PHRASES`) вставляются целиком.  \n",
    "   - Очистка пробелов вокруг пунктуации, нормализация `б/у`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "340f1825-e1a0-4fcf-bce5-95dc2e814b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 127\n"
     ]
    }
   ],
   "source": [
    "# Подготовка словаря (char2id)\n",
    "all_texts = df[\"text_no_spaces\"].tolist()\n",
    "chars = sorted(set(\"\".join(all_texts)))\n",
    "char2id = {c: i+2 for i,c in enumerate(chars)}  # 0=PAD, 1=UNK\n",
    "id2char = {i:c for c,i in char2id.items()}\n",
    "\n",
    "print(\"Размер словаря:\", len(char2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95cf59ce-31c4-482f-abb7-2e7be5283442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceDataset(Dataset):\n",
    "    def __init__(self, df, char2id, training=True):\n",
    "        self.samples = []\n",
    "        self.training = training\n",
    "        for _, row in df.iterrows():\n",
    "            text = row[\"text_no_spaces\"]\n",
    "\n",
    "            if training and \"indices\" in row:  # обучающий режим\n",
    "                indices = set(json.loads(row[\"indices\"]))\n",
    "                labels = [(1 if i in indices else 0) for i in range(len(text))]\n",
    "            else:  # режим предсказания\n",
    "                labels = [0] * len(text)\n",
    "\n",
    "            tokens = [char2id.get(c, 1) for c in text]  # 1 = UNK\n",
    "            self.samples.append((tokens, labels, text))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len = max(len(x[0]) for x in batch)\n",
    "    tokens, labels, mask, texts = [], [], [], []\n",
    "    for t, l, txt in batch:\n",
    "        pad_len = max_len - len(t)\n",
    "        tokens.append(t + [0]*pad_len)\n",
    "        labels.append(l + [0]*pad_len)\n",
    "        mask.append([1]*len(t) + [0]*pad_len)\n",
    "        texts.append(txt)\n",
    "    return (\n",
    "        torch.tensor(tokens, dtype=torch.long),\n",
    "        torch.tensor(labels, dtype=torch.long),\n",
    "        torch.tensor(mask, dtype=torch.bool),\n",
    "        texts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c3cba5a-9ee2-42ed-a950-757007524dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe809c9-6d6f-4fae-babe-f19f57a3ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSegmentation(nn.Module):\n",
    "    def __init__(self, vocab_size=2000, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(d_model, 2)  # 2 класса: 0=нет пробела, 1=пробел\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        emb = self.embedding(x) * (self.embedding.embedding_dim ** 0.5)\n",
    "        emb = self.pos_encoder(emb)\n",
    "        enc_out = self.transformer(emb, src_key_padding_mask=(~mask))\n",
    "        return self.fc(enc_out)  # [batch, seq_len, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68819937-8ad3-473f-a56e-55ef8cf6f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for tokens, labels, mask, _ in loader:\n",
    "        tokens, labels, mask = tokens.to(device), labels.to(device), mask.to(device)\n",
    "\n",
    "        logits = model(tokens, mask=mask)  # [B, L, 2]\n",
    "        loss = criterion(logits.view(-1, 2), labels.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, golds = [], []\n",
    "    with torch.no_grad():\n",
    "        for tokens, labels, mask, _ in loader:\n",
    "            tokens, labels, mask = tokens.to(device), labels.to(device), mask.to(device)\n",
    "            logits = model(tokens, mask=mask)\n",
    "            out = torch.argmax(logits, dim=-1)  # [B, L]\n",
    "\n",
    "            for p, g, m in zip(out, labels, mask):\n",
    "                length = m.sum().item()\n",
    "                preds.extend(p[:length].cpu().tolist())\n",
    "                golds.extend(g[:length].cpu().tolist())\n",
    "    return preds, golds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_dataframe(model, df, char2id, device=\"cpu\"):\n",
    "    dataset = SpaceDataset(df, char2id, training=False)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for tokens, _, mask, texts in loader:\n",
    "            tokens, mask = tokens.to(device), mask.to(device)\n",
    "            logits = model(tokens, mask=mask)\n",
    "            out = torch.argmax(logits, dim=-1)  # [B, L]\n",
    "\n",
    "            for txt, pred, m in zip(texts, out, mask):\n",
    "                length = m.sum().item()\n",
    "                spaced = []\n",
    "                for i, ch in enumerate(txt):\n",
    "                    spaced.append(ch)\n",
    "                    if pred[i].item() == 1:\n",
    "                        spaced.append(\" \")\n",
    "                results.append(\"\".join(spaced).strip())\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"spaced_text\"] = results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfaf4ee1-e443-4e03-94d4-f716f85b4281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.6399, Val F1=0.2248\n",
      "Epoch 2: Loss=0.4917, Val F1=0.3779\n",
      "Epoch 3: Loss=0.4845, Val F1=0.3919\n",
      "Epoch 4: Loss=0.4803, Val F1=0.3614\n",
      "Epoch 5: Loss=0.4797, Val F1=0.4064\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Загружаем датасет\n",
    "df_1 = pd.read_csv(\"avito_baseline_wordfreq_3.csv\")\n",
    "\n",
    "# Строим словарь символов\n",
    "all_texts = df_1[\"text_no_spaces\"].tolist()\n",
    "chars = sorted(set(\"\".join(all_texts)))\n",
    "char2id = {c: i+2 for i,c in enumerate(chars)}  # 0=PAD, 1=UNK\n",
    "\n",
    "# train/val split\n",
    "train_df, val_df = train_test_split(df_1, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = SpaceDataset(train_df, char2id, training=True)\n",
    "val_dataset = SpaceDataset(val_df, char2id, training=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Модель\n",
    "model = TransformerSegmentation(vocab_size=len(char2id)+2, d_model=128, nhead=4, num_layers=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0]).to(device), label_smoothing=0.1)\n",
    "\n",
    "for epoch in range(5):\n",
    "    loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    preds, golds = evaluate(model, val_loader, device)\n",
    "    f1 = f1_score(golds, preds)\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Val F1={f1:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"spacer_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f95bcd98-da14-4e3b-966a-d666502bae0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "      <th>length</th>\n",
       "      <th>spaced_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "      <td>15</td>\n",
       "      <td>куп люайфон1 4п ро</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "      <td>18</td>\n",
       "      <td>ищуд омв Под москов ье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "      <td>29</td>\n",
       "      <td>с д аюкв артирус меб ельюитех никой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "      <td>26</td>\n",
       "      <td>нов ыйд ив анд остав канедорог о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "      <td>15</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>Янеусну.</td>\n",
       "      <td>8</td>\n",
       "      <td>Янеусну.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>Весна-яуженегреюпио.</td>\n",
       "      <td>20</td>\n",
       "      <td>Вес на- яуженегреюп ио.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>Весна-скоровырастеттрава.</td>\n",
       "      <td>25</td>\n",
       "      <td>Вес на- с коров ырас теттрав а.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>Весна-выпосмотрите,каккрасиво.</td>\n",
       "      <td>30</td>\n",
       "      <td>Весна- в ып осмотрите,каккрасиво.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>Весна-гдемояголова?</td>\n",
       "      <td>19</td>\n",
       "      <td>Весна- г демояг олов а?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                  text_no_spaces  length  \\\n",
       "0        0                 куплюайфон14про      15   \n",
       "1        1              ищудомвПодмосковье      18   \n",
       "2        2   сдаюквартирусмебельюитехникой      29   \n",
       "3        3      новыйдивандоставканедорого      26   \n",
       "4        4                 отдамдаромкошку      15   \n",
       "...    ...                             ...     ...   \n",
       "1000  1000                        Янеусну.       8   \n",
       "1001  1001            Весна-яуженегреюпио.      20   \n",
       "1002  1002       Весна-скоровырастеттрава.      25   \n",
       "1003  1003  Весна-выпосмотрите,каккрасиво.      30   \n",
       "1004  1004             Весна-гдемояголова?      19   \n",
       "\n",
       "                              spaced_text  \n",
       "0                      куп люайфон1 4п ро  \n",
       "1                  ищуд омв Под москов ье  \n",
       "2     с д аюкв артирус меб ельюитех никой  \n",
       "3        нов ыйд ив анд остав канедорог о  \n",
       "4                         отдамдаромкошку  \n",
       "...                                   ...  \n",
       "1000                             Янеусну.  \n",
       "1001              Вес на- яуженегреюп ио.  \n",
       "1002      Вес на- с коров ырас теттрав а.  \n",
       "1003    Весна- в ып осмотрите,каккрасиво.  \n",
       "1004              Весна- г демояг олов а?  \n",
       "\n",
       "[1005 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"spacer_model.pt\"))\n",
    "model.to(device)\n",
    "\n",
    "result_df = predict_dataframe(model, df, char2id, device)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174abe7-6da3-490c-9e51-4db9db0dcd54",
   "metadata": {},
   "source": [
    "Результат не очень. Решила делать валидацию, а для этого нужно больше данных. Поэтому сгенерирую синтетические данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c055b096-1269-49a2-925b-bf21c85d36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерировано: 1842\n",
      "                      input                      target\n",
      "0      куплюкроватьнедорого      куплю кровать недорого\n",
      "1         сдамтелевизор2022         сдам телевизор 2022\n",
      "2          ищукурткавМоскве         ищу куртка в Москве\n",
      "3      ремонттелевизор14pro     ремонт телевизор 14 pro\n",
      "4       ищухолодильник14pro      ищу холодильник 14 pro\n",
      "..                      ...                         ...\n",
      "95  отдампылесосBMWнедорого  отдам пылесос BMW недорого\n",
      "96    ремонтблендердлядетей    ремонт блендер для детей\n",
      "97        куплюблендерLGб/у        куплю блендер LG б/у\n",
      "98    ищумашинаHuaweiсрочно    ищу машина Huawei срочно\n",
      "99     ищумашинаTecnoсрочно     ищу машина Tecno срочно\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "ACTIONS = [\"куплю\", \"ищу\", \"сдам\", \"сдаю\", \"продам\", \"отдам\", \"ремонт\", \"работа\"]\n",
    "ITEMS = [\n",
    "    \"телефон\", \"ноутбук\", \"диван\", \"шкаф\", \"велосипед\", \"куртка\", \"холодильник\",\n",
    "    \"стиральная машина\", \"гитара\", \"кровать\", \"телевизор\", \"пылесос\", \"микроволновка\",\n",
    "    \"обогреватель\", \"блендер\", \"плита\", \"машина\", \"игрушка\", \"пылесос робот\"\n",
    "]\n",
    "BRANDS = [\n",
    "    \"Apple\", \"Samsung\", \"Xiaomi\", \"LG\", \"Philips\", \"Sony\", \"Huawei\", \"Dyson\",\n",
    "    \"Canon\", \"Nikon\", \"Fender\", \"Toyota\", \"BMW\", \"Dell\", \"HP\", \"Asus\", \"Lenovo\",\n",
    "    \"Bosch\", \"Indesit\", \"Whirlpool\", \"Tecno\", \"Realme\", \"Poco\", \"Hotpoint\"\n",
    "]\n",
    "MODIFIERS = [\n",
    "    \"с доставкой\", \"недорого\", \"срочно\", \"б/у\", \"в Москве\", \"в Подмосковье\",\n",
    "    \"в центре города\", \"дёшево\", \"с гарантией\", \"для детей\", \"на дачу\", \"торг уместен\"\n",
    "]\n",
    "YEARS = [\"2022\", \"2023\", \"2024\", \"14 pro\", \"15 pro max\", \"13\", \"2018\", \"2020\"]\n",
    "ADJ = [\"новый\", \"б/у\", \"старый\", \"оригинальный\", \"качественный\", \"фирменный\"]\n",
    "PLACES = [\"СПб\", \"Москве\", \"Казани\", \"Екатеринбурге\", \"Нижнем Новгороде\", \"Воронеже\", \"Самаре\"]\n",
    "\n",
    "TEMPLATES = [\n",
    "    \"{act} {item} {brand}\",\n",
    "    \"{act} {item}\",\n",
    "    \"{act} {item} {mod}\",\n",
    "    \"{act} {brand} {item} {mod}\",\n",
    "    \"{act} {item} {brand} {mod}\",\n",
    "    \"{act} {adj} {brand} {item}\",\n",
    "    \"{act} {item} {year}\",\n",
    "    \"{act} {brand} {item} {year} {mod}\",\n",
    "    \"{act} {item} в {place}\",\n",
    "    \"{act} {adj} {item} {place}\"\n",
    "]\n",
    "\n",
    "# === Шум ===\n",
    "def add_typo(word):\n",
    "    if len(word) > 4 and random.random() < 0.2:\n",
    "        i = random.randint(0, len(word) - 2)\n",
    "        return word[:i] + word[i+1:]  # удаляем букву\n",
    "    return word\n",
    "\n",
    "\n",
    "# === Генератор одного батча ===\n",
    "def generate_examples(n=5000, seed=42):\n",
    "    random.seed(seed)\n",
    "    examples = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        tmpl = random.choice(TEMPLATES)\n",
    "        sample = {\n",
    "            \"act\": random.choice(ACTIONS),\n",
    "            \"item\": random.choice(ITEMS),\n",
    "            \"brand\": random.choice(BRANDS),\n",
    "            \"mod\": random.choice(MODIFIERS),\n",
    "            \"year\": random.choice(YEARS),\n",
    "            \"adj\": random.choice(ADJ),\n",
    "            \"place\": random.choice(PLACES),\n",
    "        }\n",
    "\n",
    "        target = tmpl.format(**sample).strip()\n",
    "\n",
    "        input_str = target.replace(\" \", \"\")\n",
    "        examples.append((input_str, target))\n",
    "\n",
    "    return pd.DataFrame(examples, columns=[\"input\", \"target\"])\n",
    "\n",
    "# === Генерация с несколькими seed ===\n",
    "def generate_multi_batches(n_batches=2, n_per_batch=1000):\n",
    "    dfs = []\n",
    "    for i in range(n_batches):\n",
    "        df_batch = generate_examples(n_per_batch, seed=42+i)\n",
    "        dfs.append(df_batch)\n",
    "\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    df_all = df_all.drop_duplicates().sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return df_all\n",
    "\n",
    "# === Пример использования ===\n",
    "df_syn = generate_multi_batches(n_batches=2, n_per_batch=1000)  \n",
    "df_syn.to_csv(\"synthetic_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Сгенерировано:\", len(df_syn))\n",
    "print(df_syn.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23489ba0-08a4-47d3-9076-2589954bb0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>куплюайфон14про</td>\n",
       "      <td>куплю айфон 14 про</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "      <td>ищу дом в подмосковье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "      <td>сдаю квартиру с мебе льюи техникой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "      <td>новый диван доставка недорого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>отдамдаромкошку</td>\n",
       "      <td>отдам даром кошку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Янеусну.</td>\n",
       "      <td>я не усну.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Весна-яуженегреюпио.</td>\n",
       "      <td>Весна - я уже негреюпио.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Весна-скоровырастеттрава.</td>\n",
       "      <td>Весна - скоро вы растет трава.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Весна-выпосмотрите,каккрасиво.</td>\n",
       "      <td>Весна - вы посмотрите, как красиво.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Весна-гдемояголова?</td>\n",
       "      <td>Весна - гдемоя голова?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               input                               target\n",
       "0                    куплюайфон14про                   куплю айфон 14 про\n",
       "1                 ищудомвПодмосковье                ищу дом в подмосковье\n",
       "2      сдаюквартирусмебельюитехникой   сдаю квартиру с мебе льюи техникой\n",
       "3         новыйдивандоставканедорого        новый диван доставка недорого\n",
       "4                    отдамдаромкошку                    отдам даром кошку\n",
       "...                              ...                                  ...\n",
       "1000                        Янеусну.                           я не усну.\n",
       "1001            Весна-яуженегреюпио.             Весна - я уже негреюпио.\n",
       "1002       Весна-скоровырастеттрава.       Весна - скоро вы растет трава.\n",
       "1003  Весна-выпосмотрите,каккрасиво.  Весна - вы посмотрите, как красиво.\n",
       "1004             Весна-гдемояголова?               Весна - гдемоя голова?\n",
       "\n",
       "[1005 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_seq2seq_from_baseline(csv_in,\n",
    "                                  csv_out=\"seq2seq_pairs.csv\"):\n",
    "    df = pd.read_csv(csv_in)\n",
    "\n",
    "    # оставляем только нужные столбцы\n",
    "    out_df = df[[\"text_no_spaces\", \"spaced_text\"]].rename(\n",
    "        columns={\"text_no_spaces\": \"input\", \"spaced_text\": \"target\"}\n",
    "    )\n",
    "    return out_df\n",
    "\n",
    "df_all = prepare_seq2seq_from_baseline(\"avito_baseline_wordfreq_3.csv\")\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "49a70c27-d996-4475-88af-4e710ced54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn = pd.read_csv(\"synthetic_dataset.csv\")        \n",
    "df_real = pd.read_csv(\"avito_baseline_wordfreq_3.csv\")\n",
    "\n",
    "df_syn_train, df_syn_val = train_test_split(df_syn, test_size=0.1, random_state=42)\n",
    "\n",
    "df_real_train, test_real = train_test_split(df_real, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4adcad98-166e-4777-9405-1b00d843182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Модель с dropout ===\n",
    "class TransformerSegmentation(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, dim_feedforward=4*d_model, dropout=dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x == 0)\n",
    "        emb = self.embedding(x).transpose(0, 1)  # [seq, batch, d_model]\n",
    "        out = self.encoder(emb, src_key_padding_mask=mask)\n",
    "        out = self.fc(out.transpose(0, 1))\n",
    "        return out\n",
    "\n",
    "\n",
    "# === Функции обучения ===\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out.view(-1, 2), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, golds = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out.argmax(-1).cpu().numpy().ravel().tolist()\n",
    "            gold = y.cpu().numpy().ravel().tolist()\n",
    "            preds.extend(pred)\n",
    "            golds.extend(gold)\n",
    "    valid = [i for i, g in enumerate(golds) if g != -100]\n",
    "    return f1_score([golds[i] for i in valid], [preds[i] for i in valid])\n",
    "\n",
    "\n",
    "# === Random Search ===\n",
    "def random_search(train_dataset, val_dataset, vocab_size, device, trials=15):\n",
    "    best_f1 = -1\n",
    "    best_params = None\n",
    "\n",
    "    for t in range(trials):\n",
    "        # === случайные гиперпараметры ===\n",
    "        d_model = random.choice([128, 192, 256])\n",
    "        num_layers = random.choice([2, 3, 4])\n",
    "        dropout = random.choice([0.1, 0.2, 0.3, 0.4])\n",
    "        weight_val = random.choice([8.0, 10.0, 12.0, 15.0])\n",
    "        lr = random.choice([5e-4, 1e-3, 2e-3])\n",
    "        batch_size = random.choice([16, 32, 64])\n",
    "\n",
    "        print(f\"\\n=== Trial {t+1} ===\")\n",
    "        print(f\"d_model={d_model}, num_layers={num_layers}, dropout={dropout}, \"\n",
    "              f\"weight={weight_val}, lr={lr}, batch_size={batch_size}\")\n",
    "\n",
    "        # даталоадеры\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        # модель\n",
    "        model = TransformerSegmentation(\n",
    "            vocab_size=vocab_size,\n",
    "            d_model=d_model,\n",
    "            nhead=4,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, weight_val]).to(device))\n",
    "\n",
    "        # обучение (коротко — 5 эпох)\n",
    "        for epoch in range(5):\n",
    "            loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            f1 = evaluate(model, val_loader, device)\n",
    "            print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Val F1={f1:.4f}\")\n",
    "\n",
    "        # сохраняем лучшую модель\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = (d_model, num_layers, dropout, weight_val, lr, batch_size)\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            print(\">>> New best model saved!\")\n",
    "\n",
    "    print(\"\\n=== Лучшие гиперпараметры ===\")\n",
    "    print(f\"Val F1={best_f1:.4f}\")\n",
    "    print(f\"d_model={best_params[0]}, num_layers={best_params[1]}, dropout={best_params[2]}, \"\n",
    "          f\"weight={best_params[3]}, lr={best_params[4]}, batch_size={best_params[5]}\")\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "acf6c9fd-e7eb-4339-9135-6dc4bf282acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trial 1 ===\n",
      "d_model=128, num_layers=3, dropout=0.3, weight=10.0, lr=0.002, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4584, Val F1=0.4866\n",
      "Epoch 2: Loss=0.3258, Val F1=0.5467\n",
      "Epoch 3: Loss=0.2890, Val F1=0.5693\n",
      "Epoch 4: Loss=0.2693, Val F1=0.5919\n",
      "Epoch 5: Loss=0.2655, Val F1=0.6046\n",
      ">>> New best model saved!\n",
      "\n",
      "=== Trial 2 ===\n",
      "d_model=128, num_layers=4, dropout=0.3, weight=15.0, lr=0.001, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.3991, Val F1=0.4499\n",
      "Epoch 2: Loss=0.3088, Val F1=0.5007\n",
      "Epoch 3: Loss=0.2757, Val F1=0.5065\n",
      "Epoch 4: Loss=0.2558, Val F1=0.5846\n",
      "Epoch 5: Loss=0.2458, Val F1=0.5495\n",
      "\n",
      "=== Trial 3 ===\n",
      "d_model=128, num_layers=4, dropout=0.4, weight=12.0, lr=0.0005, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4472, Val F1=0.4378\n",
      "Epoch 2: Loss=0.3430, Val F1=0.4940\n",
      "Epoch 3: Loss=0.3004, Val F1=0.5281\n",
      "Epoch 4: Loss=0.2756, Val F1=0.5844\n",
      "Epoch 5: Loss=0.2553, Val F1=0.5772\n",
      "\n",
      "=== Trial 4 ===\n",
      "d_model=192, num_layers=2, dropout=0.3, weight=10.0, lr=0.002, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4662, Val F1=0.4710\n",
      "Epoch 2: Loss=0.3367, Val F1=0.5404\n",
      "Epoch 3: Loss=0.3000, Val F1=0.5472\n",
      "Epoch 4: Loss=0.2845, Val F1=0.5594\n",
      "Epoch 5: Loss=0.2718, Val F1=0.5702\n",
      "\n",
      "=== Trial 5 ===\n",
      "d_model=256, num_layers=4, dropout=0.4, weight=8.0, lr=0.0005, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4578, Val F1=0.4950\n",
      "Epoch 2: Loss=0.3313, Val F1=0.5650\n",
      "Epoch 3: Loss=0.2936, Val F1=0.5812\n",
      "Epoch 4: Loss=0.2779, Val F1=0.6002\n",
      "Epoch 5: Loss=0.2623, Val F1=0.6504\n",
      ">>> New best model saved!\n",
      "\n",
      "=== Trial 6 ===\n",
      "d_model=256, num_layers=2, dropout=0.1, weight=12.0, lr=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.5160, Val F1=0.4482\n",
      "Epoch 2: Loss=0.3260, Val F1=0.5286\n",
      "Epoch 3: Loss=0.2766, Val F1=0.5767\n",
      "Epoch 4: Loss=0.2553, Val F1=0.5802\n",
      "Epoch 5: Loss=0.2411, Val F1=0.5671\n",
      "\n",
      "=== Trial 7 ===\n",
      "d_model=128, num_layers=3, dropout=0.2, weight=8.0, lr=0.001, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4651, Val F1=0.5015\n",
      "Epoch 2: Loss=0.3157, Val F1=0.5884\n",
      "Epoch 3: Loss=0.2691, Val F1=0.6067\n",
      "Epoch 4: Loss=0.2411, Val F1=0.6395\n",
      "Epoch 5: Loss=0.2271, Val F1=0.6675\n",
      ">>> New best model saved!\n",
      "\n",
      "=== Trial 8 ===\n",
      "d_model=128, num_layers=3, dropout=0.2, weight=10.0, lr=0.002, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4398, Val F1=0.5408\n",
      "Epoch 2: Loss=0.3099, Val F1=0.5491\n",
      "Epoch 3: Loss=0.2859, Val F1=0.5829\n",
      "Epoch 4: Loss=0.2796, Val F1=0.5490\n",
      "Epoch 5: Loss=0.2699, Val F1=0.5828\n",
      "\n",
      "=== Trial 9 ===\n",
      "d_model=192, num_layers=4, dropout=0.4, weight=10.0, lr=0.0005, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4517, Val F1=0.4804\n",
      "Epoch 2: Loss=0.3373, Val F1=0.5325\n",
      "Epoch 3: Loss=0.2936, Val F1=0.5631\n",
      "Epoch 4: Loss=0.2688, Val F1=0.5933\n",
      "Epoch 5: Loss=0.2542, Val F1=0.6406\n",
      "\n",
      "=== Trial 10 ===\n",
      "d_model=128, num_layers=3, dropout=0.1, weight=10.0, lr=0.002, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4774, Val F1=0.4940\n",
      "Epoch 2: Loss=0.3089, Val F1=0.5487\n",
      "Epoch 3: Loss=0.2541, Val F1=0.6265\n",
      "Epoch 4: Loss=0.2334, Val F1=0.5905\n",
      "Epoch 5: Loss=0.2255, Val F1=0.6177\n",
      "\n",
      "=== Trial 11 ===\n",
      "d_model=192, num_layers=4, dropout=0.2, weight=12.0, lr=0.0005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.5025, Val F1=0.4244\n",
      "Epoch 2: Loss=0.3519, Val F1=0.5060\n",
      "Epoch 3: Loss=0.2891, Val F1=0.5486\n",
      "Epoch 4: Loss=0.2539, Val F1=0.5658\n",
      "Epoch 5: Loss=0.2269, Val F1=0.5875\n",
      "\n",
      "=== Trial 12 ===\n",
      "d_model=128, num_layers=3, dropout=0.1, weight=15.0, lr=0.0005, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.3735, Val F1=0.5034\n",
      "Epoch 2: Loss=0.2601, Val F1=0.5624\n",
      "Epoch 3: Loss=0.2167, Val F1=0.6235\n",
      "Epoch 4: Loss=0.1988, Val F1=0.6178\n",
      "Epoch 5: Loss=0.1805, Val F1=0.6464\n",
      "\n",
      "=== Trial 13 ===\n",
      "d_model=192, num_layers=3, dropout=0.3, weight=10.0, lr=0.0005, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4275, Val F1=0.5154\n",
      "Epoch 2: Loss=0.3076, Val F1=0.5910\n",
      "Epoch 3: Loss=0.2617, Val F1=0.5975\n",
      "Epoch 4: Loss=0.2417, Val F1=0.6371\n",
      "Epoch 5: Loss=0.2280, Val F1=0.6423\n",
      "\n",
      "=== Trial 14 ===\n",
      "d_model=256, num_layers=2, dropout=0.4, weight=12.0, lr=0.001, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4258, Val F1=0.5104\n",
      "Epoch 2: Loss=0.3251, Val F1=0.5253\n",
      "Epoch 3: Loss=0.2997, Val F1=0.5361\n",
      "Epoch 4: Loss=0.2941, Val F1=0.5356\n",
      "Epoch 5: Loss=0.2860, Val F1=0.5541\n",
      "\n",
      "=== Trial 15 ===\n",
      "d_model=192, num_layers=3, dropout=0.4, weight=12.0, lr=0.0005, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.4254, Val F1=0.4775\n",
      "Epoch 2: Loss=0.3285, Val F1=0.5259\n",
      "Epoch 3: Loss=0.2854, Val F1=0.5631\n",
      "Epoch 4: Loss=0.2673, Val F1=0.5401\n",
      "Epoch 5: Loss=0.2548, Val F1=0.5493\n",
      "\n",
      "=== Лучшие гиперпараметры ===\n",
      "Val F1=0.6675\n",
      "d_model=128, num_layers=3, dropout=0.2, weight=8.0, lr=0.001, batch_size=32\n",
      "                      text_no_spaces  \\\n",
      "0                    куплюайфон14про   \n",
      "1                 ищудомвПодмосковье   \n",
      "2      сдаюквартирусмебельюитехникой   \n",
      "3         новыйдивандоставканедорого   \n",
      "4                    отдамдаромкошку   \n",
      "5              работавМосквеудаленно   \n",
      "6              куплютелевизорPhilips   \n",
      "7            ищугрузчиковдляпереезда   \n",
      "8               ремонтквартирподключ   \n",
      "9                     куплюноутбукHP   \n",
      "10                 ищуквартирууметро   \n",
      "11         новаямикроволновкаSamsung   \n",
      "12             срочнопродамвелосипед   \n",
      "13                 куплюгитаруFender   \n",
      "14           ищурепетиторапобиологии   \n",
      "15         сдаюгаражнадлительныйсрок   \n",
      "16                      куплюдиванбу   \n",
      "17  ищумастерапоремонтухолодильников   \n",
      "18          новыйшкафдоставкасегодня   \n",
      "19                        куплюXoxne   \n",
      "\n",
      "                                  spaced_text  \n",
      "0                        куплю а йф он 14 про  \n",
      "1                     ищу дом в Подм осков ье  \n",
      "2        с даю к вартирус мебель ю итехник ой  \n",
      "3              н овый диван доставкан едорого  \n",
      "4                         отда м да ром кошку  \n",
      "5                 р а бота в Москв еуда ленно  \n",
      "6                     куплю телевизор Philips  \n",
      "7               ищу гр у зчиков для пер еезда  \n",
      "8                    ремонт ква рт ирподклю ч  \n",
      "9                           к уплю ноутбук HP  \n",
      "10                    ищу ква рт иру у мет ро  \n",
      "11               нова я микроволновка Samsung  \n",
      "12                   срочнопрод а м велосипед  \n",
      "13                        куплю гита руFender  \n",
      "14                ищу репет ит ора побиологии  \n",
      "15                сдаю гаражнадлительный срок  \n",
      "16                           куплю див а н бу  \n",
      "17  ищу м а ст ера порем онт у холодильник ов  \n",
      "18                 новый шкаф доставкасегодня  \n",
      "19                              куплю Xox n e  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "best_params = random_search(train_dataset, val_dataset, vocab_size=len(char2id)+2, device=device, trials=15)\n",
    "\n",
    "# Загружаем лучшую модель\n",
    "model = TransformerSegmentation(\n",
    "    vocab_size=len(char2id)+2,\n",
    "    d_model=best_params[0],\n",
    "    nhead=4,\n",
    "    num_layers=best_params[1],\n",
    "    dropout=best_params[2]\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# Проверка на исходных данных\n",
    "result_df = predict_dataframe(model, df, char2id, device)\n",
    "print(result_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0712768d-4484-48ee-b284-28b36bcb65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1: Loss=0.1060, Val F1=0.4280\n",
      "Pretrain Epoch 2: Loss=0.0429, Val F1=0.5838\n",
      "Pretrain Epoch 3: Loss=0.0345, Val F1=0.6584\n",
      "Pretrain Epoch 4: Loss=0.0301, Val F1=0.6634\n",
      "Pretrain Epoch 5: Loss=0.0274, Val F1=0.7045\n",
      "Pretrain Epoch 6: Loss=0.0259, Val F1=0.7232\n",
      "Pretrain Epoch 7: Loss=0.0250, Val F1=0.6861\n",
      "Pretrain Epoch 8: Loss=0.0238, Val F1=0.6718\n",
      "Pretrain Epoch 9: Loss=0.0232, Val F1=0.6856\n",
      "Pretrain Epoch 10: Loss=0.0224, Val F1=0.6928\n",
      "Finetune Epoch 1: Loss=0.0725, Val F1=0.0297\n",
      "Finetune Epoch 2: Loss=0.0599, Val F1=0.1281\n",
      "Finetune Epoch 3: Loss=0.0582, Val F1=0.3039\n",
      "Finetune Epoch 4: Loss=0.0574, Val F1=0.2488\n",
      "Finetune Epoch 5: Loss=0.0554, Val F1=0.2877\n",
      "Finetune Epoch 6: Loss=0.0563, Val F1=0.3719\n",
      "Finetune Epoch 7: Loss=0.0546, Val F1=0.2933\n",
      "Finetune Epoch 8: Loss=0.0540, Val F1=0.3204\n",
      "Finetune Epoch 9: Loss=0.0532, Val F1=0.4039\n",
      "Finetune Epoch 10: Loss=0.0543, Val F1=0.3167\n",
      "Finetune Epoch 11: Loss=0.0519, Val F1=0.3084\n",
      "Finetune Epoch 12: Loss=0.0525, Val F1=0.3527\n",
      "Finetune Epoch 13: Loss=0.0521, Val F1=0.3363\n",
      "Finetune Epoch 14: Loss=0.0511, Val F1=0.3036\n",
      "Finetune Epoch 15: Loss=0.0507, Val F1=0.3277\n",
      "Finetune Epoch 16: Loss=0.0506, Val F1=0.3193\n",
      "Finetune Epoch 17: Loss=0.0499, Val F1=0.3482\n",
      "Finetune Epoch 18: Loss=0.0497, Val F1=0.3084\n",
      "Finetune Epoch 19: Loss=0.0485, Val F1=0.3793\n",
      "Finetune Epoch 20: Loss=0.0493, Val F1=0.3738\n",
      "Лучший F1: 0.7231740306582507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                          input                       spaced_text\n",
      "0   0                куплюайфон14про                 куплю айфон14 про\n",
      "1   1             ищудомвПодмосковье             ищу домв Подмосков ье\n",
      "2   2  сдаюквартирусмебельюитехникой  сдаю квартирусмебелью итехник ой\n",
      "3   3     новыйдивандоставканедорого       новый дивандоставканедорого\n",
      "4   4                отдамдаромкошку                 отдам даром кошку\n",
      "5   5          работавМосквеудаленно         ра бота вМоскв еуда ленно\n",
      "6   6          куплютелевизорPhilips           куплю телевизор Philips\n",
      "7   7        ищугрузчиковдляпереезда       ищу гр узчиковдля пер еезда\n",
      "8   8           ремонтквартирподключ            ремонтква ртирподклю ч\n",
      "9   9                 куплюноутбукHP                   куплю ноутбукHP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== 1. Словарь символов ====\n",
    "all_texts = pd.concat([df_syn, df_real])[\"input\"].astype(str).fillna(\"\").tolist()\n",
    "chars = sorted(set(\"\".join(all_texts)))\n",
    "char2id = {c: i+2 for i,c in enumerate(chars)}  # 0=PAD, 1=UNK\n",
    "\n",
    "# ==== 2. Датасет ====\n",
    "class SpaceDataset(Dataset):\n",
    "    def __init__(self, df, char2id, training=True, input_column=\"input\", target_column=\"target\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.char2id = char2id\n",
    "        self.training = training\n",
    "        self.input_column = input_column\n",
    "        self.target_column = target_column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # вход\n",
    "        text_in = str(row[self.input_column])\n",
    "        x = [self.char2id.get(ch, 1) for ch in text_in]\n",
    "\n",
    "        if self.training:\n",
    "            text_out = str(row[self.target_column])\n",
    "\n",
    "            y = []\n",
    "            j = 0\n",
    "            for ch in text_out:\n",
    "                if ch == \" \":\n",
    "                    # ставим метку пробела на предыдущий символ\n",
    "                    if j > 0:\n",
    "                        y[j-1] = 1\n",
    "                elif j < len(text_in) and ch == text_in[j]:\n",
    "                    # совпадает с input → добавляем символ\n",
    "                    y.append(0)\n",
    "                    j += 1\n",
    "                else:\n",
    "                    # если символ есть в target, но его нет в input (например /)\n",
    "                    # просто пропускаем\n",
    "                    continue\n",
    "\n",
    "            # safety check\n",
    "            if len(y) != len(x):\n",
    "                y = y[:len(x)]  # обрезаем\n",
    "                while len(y) < len(x):\n",
    "                    y.append(0)\n",
    "\n",
    "            return torch.tensor(x), torch.tensor(y)\n",
    "        else:\n",
    "            return torch.tensor(x)\n",
    "            \n",
    "def collate_fn(batch):\n",
    "    if isinstance(batch[0], tuple):\n",
    "        # обучение\n",
    "        xs, ys = zip(*batch)\n",
    "        maxlen = max(len(x) for x in xs)\n",
    "        x_pad = torch.zeros(len(xs), maxlen, dtype=torch.long)\n",
    "        y_pad = torch.full((len(xs), maxlen), -100, dtype=torch.long)\n",
    "        for i,(x,y) in enumerate(zip(xs,ys)):\n",
    "            x_pad[i,:len(x)] = x\n",
    "            y_pad[i,:len(y)] = y\n",
    "        return x_pad, y_pad\n",
    "    else:\n",
    "        # предсказание\n",
    "        maxlen = max(len(x) for x in batch)\n",
    "        x_pad = torch.zeros(len(batch), maxlen, dtype=torch.long)\n",
    "        for i,x in enumerate(batch):\n",
    "            x_pad[i,:len(x)] = x\n",
    "        return x_pad\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = self.ce(logits, targets)  # обычный CE\n",
    "        pt = torch.exp(-ce_loss)            # вероятность правильного класса\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "# ==== 3. Модель ====\n",
    "class TransformerSegmentation(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=4, num_layers=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=512, dropout=dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x==0)\n",
    "        emb = self.embedding(x).transpose(0,1)\n",
    "        out = self.encoder(emb, src_key_padding_mask=mask)\n",
    "        out = self.fc(out.transpose(0,1))\n",
    "        return out\n",
    "\n",
    "# ==== 4. Функции обучения ====\n",
    "def train_epoch(model, loader, optim, criterion):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out.view(-1,2), y.view(-1))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += loss.item()\n",
    "    return total/len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, golds = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out.argmax(-1).cpu().numpy().ravel().tolist()\n",
    "            gold = y.cpu().numpy().ravel().tolist()\n",
    "            preds.extend(pred)\n",
    "            golds.extend(gold)\n",
    "    valid = [i for i,g in enumerate(golds) if g!=-100]\n",
    "    return f1_score([golds[i] for i in valid], [preds[i] for i in valid])\n",
    "\n",
    "def postprocess_spaced(spaced: str) -> str:\n",
    "    # Разбиваем по пробелам\n",
    "    tokens = spaced.split()\n",
    "\n",
    "    # Правила\n",
    "    tokens = fix_suffix(tokens)\n",
    "    tokens = fix_short(tokens)\n",
    "    tokens = fix_bigrams(tokens)\n",
    "\n",
    "    # Склеиваем\n",
    "    spaced = \" \".join(tokens)\n",
    "\n",
    "    # Бренды и пунктуация\n",
    "    spaced = fix_brands(spaced)\n",
    "    spaced = re.sub(r\"\\s+,\", \",\", spaced)\n",
    "    spaced = re.sub(r\",(?=\\S)\", \", \", spaced)\n",
    "    spaced = re.sub(r\"\\s*-\\s*\", \" - \", spaced)\n",
    "    spaced = re.sub(r\"\\s+([.!?;:])\", r\"\\1\", spaced)\n",
    "    spaced = re.sub(r\"\\s{2,}\", \" \", spaced)\n",
    "\n",
    "    return spaced.strip()\n",
    "\n",
    "def predict_single(model, text, char2id, device):\n",
    "    model.eval()\n",
    "    x = torch.tensor([char2id.get(ch, 1) for ch in text], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)  # (1, seq_len, 2)\n",
    "        pred = logits.argmax(-1).squeeze(0).cpu().numpy()\n",
    "\n",
    "    # вставляем пробелы ПОСЛЕ символов\n",
    "    spaced = []\n",
    "    for i, ch in enumerate(text):\n",
    "        spaced.append(ch)\n",
    "        if pred[i] == 1:\n",
    "            spaced.append(\" \")\n",
    "    spaced = postprocess(\"\".join(spaced).strip())\n",
    "    return \"\".join(spaced).strip()\n",
    "\n",
    "\n",
    "\n",
    "def predict_dataframe(model, df, char2id, device, input_column=\"text_no_spaces\"):\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text_in = str(row[input_column])\n",
    "        spaced_text = predict_single(model, text_in, char2id, device)\n",
    "        results.append({\n",
    "            \"id\": row.get(\"id\", None),\n",
    "            \"input\": text_in,\n",
    "            \"spaced_text\": spaced_text\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==== 5. Split ====\n",
    "df_syn_train, df_syn_val = train_test_split(df_syn, test_size=0.1, random_state=42)\n",
    "df_real_train, df_real_val = train_test_split(df_real, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(SpaceDataset(df_syn_train, char2id, True), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(SpaceDataset(df_syn_val, char2id, True), batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "real_loader  = DataLoader(SpaceDataset(df_real_train, char2id, True, input_column=\"text_no_spaces\", target_column=\"spaced_text\"),\n",
    "                          batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "real_val_loader = DataLoader(SpaceDataset(df_real_val, char2id, True, input_column=\"text_no_spaces\", target_column=\"spaced_text\"),\n",
    "                             batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# ==== 6. Обучение ====\n",
    "model = TransformerSegmentation(vocab_size=len(char2id)+2).to(device)\n",
    "criterion = FocalLoss(alpha=1.0, gamma=2.0).to(device)\n",
    "\n",
    "best_f1 = 0\n",
    "best_model_path = \"best_model.pt\"\n",
    "\n",
    "# Этап 1: синтетика\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(model, train_loader, optim, criterion)\n",
    "    f1 = evaluate(model, val_loader)\n",
    "    print(f\"Pretrain Epoch {epoch+1}: Loss={loss:.4f}, Val F1={f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "# Этап 2: реальные\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "for epoch in range(20):  # больше эпох на реальных\n",
    "    loss = train_epoch(model, real_loader, optim, criterion)\n",
    "    f1 = evaluate(model, real_val_loader)\n",
    "    print(f\"Finetune Epoch {epoch+1}: Loss={loss:.4f}, Val F1={f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(\"Лучший F1:\", best_f1)\n",
    "\n",
    "model = TransformerSegmentation(vocab_size=len(char2id)+2).to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "result_df = predict_dataframe(model, df, char2id, device, input_column=\"text_no_spaces\")\n",
    "print(result_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c29290-3e4b-4cf7-910c-c50ff151e4fa",
   "metadata": {},
   "source": [
    "Добавлю постпроцессинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef7721b1-b513-4489-bb0e-6e92a5c5f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND_PATTERN = re.compile(r\"(\" + \"|\".join(map(re.escape, BRANDS)) + r\")\", re.IGNORECASE)\n",
    "\n",
    "PHRASE_MAP = {re.sub(r\"\\s+\", \"\", p): p for p in COMMON_PHRASES}\n",
    "PHRASE_REGEX = re.compile(\"|\".join(map(re.escape, PHRASE_MAP.keys())), re.I)\n",
    "\n",
    "CONJUNCTIONS = {\"и\",\"а\",\"но\",\"или\",\"да\",\"чтобы\",\"как\"}\n",
    "\n",
    "SUFFIXES = {\"ой\",\"ые\",\"ие\",\"ов\",\"ам\",\"ем\",\"ах\",\"ях\",\"ий\",\"ый\",\"ая\",\"яя\"}\n",
    "\n",
    "# триггеры для склеивания с последующим словом\n",
    "BIGRAM_TRIGGERS = {\"ищу\",\"куплю\",\"сдаю\",\"продам\",\"отдам\",\"работа\",\"ремонт\"}\n",
    "\n",
    "\n",
    "def fix_suffix(tokens):\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i+1 < len(tokens) and tokens[i+1].lower() in SUFFIXES:\n",
    "            out.append(tokens[i] + tokens[i+1])\n",
    "            i += 2\n",
    "        else:\n",
    "            out.append(tokens[i])\n",
    "            i += 1\n",
    "    return out\n",
    "\n",
    "\n",
    "def fix_bigrams(tokens):\n",
    "    out = []\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if i > 0 and out[-1].lower() in BIGRAM_TRIGGERS and len(tok) > 2:\n",
    "            out[-1] = out[-1] + \" \" + tok\n",
    "        else:\n",
    "            out.append(tok)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fix_short(tokens):\n",
    "    \"\"\"\n",
    "    Склеиваем слишком короткие токены (1–2 символа), если они не предлоги/местоимения.\n",
    "    \"\"\"\n",
    "    out, buf = [], []\n",
    "    for t in tokens:\n",
    "        if len(t) <= 2 and t.lower() not in PREPOSITIONS and t.lower() not in PRONOUNS:\n",
    "            buf.append(t)\n",
    "        else:\n",
    "            if buf:\n",
    "                out.append(\"\".join(buf))\n",
    "                buf.clear()\n",
    "            out.append(t)\n",
    "    if buf:\n",
    "        out.append(\"\".join(buf))\n",
    "    return out\n",
    "\n",
    "\n",
    "def fix_brands(spaced: str) -> str:\n",
    "    def repl(m):\n",
    "        return BRANDS.get(m.group(1).lower(), m.group(1))\n",
    "    return re.sub(r\"\\b(hp|ibm|lg|philips|sony)\\b\", repl, spaced, flags=re.I)\n",
    "\n",
    "\n",
    "def postprocess_spaced(spaced: str) -> str:\n",
    "    # Разбиваем по пробелам\n",
    "    tokens = spaced.split()\n",
    "\n",
    "    # Правила\n",
    "    tokens = fix_suffix(tokens)\n",
    "    tokens = fix_short(tokens)\n",
    "    tokens = fix_bigrams(tokens)\n",
    "\n",
    "    # Склеиваем\n",
    "    spaced = \" \".join(tokens)\n",
    "\n",
    "    # Бренды и пунктуация\n",
    "    spaced = fix_brands(spaced)\n",
    "    spaced = re.sub(r\"\\s+,\", \",\", spaced)\n",
    "    spaced = re.sub(r\",(?=\\S)\", \", \", spaced)\n",
    "    spaced = re.sub(r\"\\s*-\\s*\", \" - \", spaced)\n",
    "    spaced = re.sub(r\"\\s+([.!?;:])\", r\"\\1\", spaced)\n",
    "    spaced = re.sub(r\"\\s{2,}\", \" \", spaced)\n",
    "\n",
    "    return spaced.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5d74ae7e-5df9-4a73-8071-a291de84d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHRASE_MAP = {re.sub(r\"\\s+\", \"\", p): p for p in COMMON_PHRASES}\n",
    "\n",
    "\n",
    "SUF1 = {\"у\",\"а\",\"о\",\"е\",\"ы\",\"и\",\"ю\",\"я\"}\n",
    "SUF2 = {\"ов\",\"ев\",\"ой\",\"ей\",\"ий\",\"ый\",\"ая\",\"яя\",\"ью\"}\n",
    "\n",
    "def hybrid_segment(text, model, char2id, device, \n",
    "                   brands=BRANDS, phrase_map=PHRASE_MAP):\n",
    "    \"\"\"\n",
    "    Гибридное восстановление пробелов:\n",
    "    Нейросеть (TransformerSegmentation) + эвристики (словари, частоты).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # === 1. Подготовка ===\n",
    "    x = torch.tensor([char2id.get(ch, 1) for ch in text], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    mask = (x == 0)\n",
    "    \n",
    "    # === 2. Предсказание модели ===\n",
    "    with torch.no_grad():\n",
    "        logits = model(tokens)\n",
    "        pred = logits.argmax(-1).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # вставляем пробелы\n",
    "    spaced = []\n",
    "    for i, ch in enumerate(text):\n",
    "        if pred[i] == 1:\n",
    "            spaced.append(\" \")\n",
    "        spaced.append(ch)\n",
    "    spaced_text = \"\".join(spaced).strip()\n",
    "    \n",
    "    # === 3. Эвристическая дообработка ===\n",
    "    # фразы\n",
    "    spaced_text = PHRASE_REGEX.sub(\n",
    "        lambda m: phrase_map.get(m.group(0).lower(), m.group(0)), spaced_text\n",
    "    )\n",
    "    # цифры/заглавные\n",
    "    spaced_text = heuristic_segment_basic(spaced_text)\n",
    "    # токенизация\n",
    "    tokens = MIX_TOKENIZER.findall(spaced_text)\n",
    "    new_tokens = []\n",
    "    for tok in tokens:\n",
    "        if RU_CHUNK.fullmatch(tok):\n",
    "            seg = segment_alpha_chunk(tok)\n",
    "            seg = fix_oversegmentation(seg)\n",
    "            seg = fix_bigrams(seg)\n",
    "            new_tokens.extend(seg)\n",
    "        else:\n",
    "            new_tokens.append(tok)\n",
    "    \n",
    "    spaced_text = \" \".join(new_tokens)\n",
    "    # исправления\n",
    "    spaced_text = fix_suffix_splits(spaced_text)\n",
    "    spaced_text = fix_brands(spaced_text)\n",
    "    spaced_text = fix_punctuation(spaced_text)\n",
    "    \n",
    "    return spaced_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fce514-919b-4cf4-957b-17c5f982ad9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618cadc-194d-4ea2-848b-dfe32383b224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef408e-a2a5-46bd-a3d8-4baf2d17ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88b625-bbc2-4df1-9bca-d59b02045d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7190a0-0e89-4477-b987-cf746cfbb482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264fb16-5357-485e-be2d-7b0d2aa70624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696365e-cd52-4ce0-90f8-8b11bda35bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312fd9f9-bb48-49f9-9d8e-70fd8e2601e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7dadf-9a72-4ce6-93a2-03af039ee1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26d5a8-e44e-43c0-9bfa-06d3fd3f9145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bcce3b-c196-499b-ab79-c465b3a3b9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddb616-2451-4cba-8ffa-b40c0985660b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504688a-391e-4c60-acf5-ebf067758223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e34b3d-86dc-4710-a296-b738a1ef42ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de5463-8158-4b4a-bbd1-e345aeed6e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1973f1-9edd-4ae8-bf3d-99c032a99ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
